{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"support_files/images/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">Python Bootcamp</h1> \n",
    "<h3 align=\"center\">August 20-21, 2022</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<center><h1>Introduction to Pandas</h1></center>\n",
    "\n",
    "\n",
    "**<code>[pandas](https://pandas.pydata.org/)</code>** is a library with high-level data structures and manipulation tools:\n",
    "\n",
    "**DataFrame Object**\n",
    "    \n",
    "A Pandas DataFrame is a two-dimensional size-mutable, potentially heterogeneous tabular data structure that holds ***relational data***.\n",
    "\n",
    "Data is aligned in a tabular fashion with labeled rows and columns like a spreadsheet or SQL table, or a dict of Series objects. Essentially, a Pandas DataFrame consists of three components, the data, rows, and columns.\n",
    "***\n",
    "Key takeaways: \n",
    "* Represents a tabular, spreadsheet-like data structure\n",
    "* Ordered collection of columns\n",
    "* Each column can be a different value type (numeric, string, boolean, etc.)\n",
    "* holds relational data\n",
    "\n",
    "<img src=\"support_files/images/pandas/dataframe_example.png\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<center><h1>Relational Data</h1></center>\n",
    "\n",
    "Pandas dataframes/tables typically contain relational data. Relational data is data that captures associations or relationships between data points. This is often expressed as a table with columns indicating the quantities related. For example, \"First names\" are associated with \"Last Names\".\n",
    "    \n",
    "\n",
    "This is a table with two columns, one column for First Name and one column for Last Name. For the pedantic, a \"relation\" is a table with no duplicate entries. \n",
    "\n",
    "<img src=\"support_files/images/pandas/pandas_relational_df.png\" width='250'>  \n",
    "    \n",
    "This is a table with two columns, one column for First Name and one column for Last Name.\n",
    "\n",
    "\n",
    "For the pedantic, a \"relation\" is a table with no duplicate entries.  We might, for example, have two John Smiths.  We can try to eliminate this collision problem by introducing an **Index**.\n",
    "\n",
    "<img src=\"support_files/images/pandas/pandas_student_df_with_index.png\" width='300'>  \n",
    "    \n",
    "**A brief note on row vs index**\n",
    "In this notebook and lecture we will use the terms row number and index. For many contexts these terms are interchangable, however due to pandas nomenclature around different ways of slicing and dicing data, we will have distinct meanings for these\n",
    "\n",
    "row number: the number of the row starting with row 0\n",
    "index: label given to a specific row\n",
    " \n",
    "    \n",
    "<img src=\"support_files/images/pandas/pandas_relation_df_generic.png\" width='250'>       \n",
    "   \n",
    "In the above table we have added an \"Index\".  The `DataFrame` object in Python is a representation of a table with these components.  It is composed of rows, each with an index, and labeled columns. \n",
    "    \n",
    "<br>\n",
    "In a general `DataFrame`, we might have many different relations captured in the same table.  For example, a `DataFrame` with student data from a school might look something like this:\n",
    "    \n",
    "<img src=\"support_files/images/pandas/pandas_relational_student_df.png\" width='500'>  \n",
    "\n",
    "<br>\n",
    "\n",
    "**Data Representation**\n",
    "\n",
    "When thinking about data analysis, note that the above table already gives us something to think about regarding how choices of data representation affect conclusions.  What if someone only has one name?  What if they have a name that isn't easily represented as \"First name/Last name\"?  What if they come from a culture that keeps track of multiple names?  \n",
    "\n",
    "Note there is a Gender column.  What if the person who constructed this data had created this column as `isFemale`?  \n",
    "\n",
    "When interacting with tables and `DataFrames`, it is important to keep these issues in mind.  Structural choices about data can and will affect conclusions.  Whenever you make a `DataFrame` or use one someone else has constructed for you, you are making or dealing with these kinds of choices.\n",
    "    \n",
    "There are standard operations related to questions you might have about the students in the above `DataFrame`. \n",
    "<ul>\n",
    "    <li> Which students took Physics?  </li>\n",
    "    <li> Which students got an A in any course?  Which Students from the University of Washington got an A or B in either Physics or History? </li>\n",
    "    </ul>\n",
    "\n",
    "The `DataFrame` object has operations that allow these kinds of questions to be answered in a computationally efficient manner. These are covered in this tutorial.\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "<center><h2>Many different relations</h2></center>\n",
    "\n",
    "If we only needed to subselect from one table, we wouldn't really need something like `pandas` and its `DataFrame` (though it is helpful for this!).  The real power of the `DataFrame` object appears when we have multiple relations, i.e. multiple `DataFrame`s and we wish to combine them in some way.\n",
    "\n",
    "For example we might have `DataFrame`s that represent student Grades, or Professors, or Schools.\n",
    "\n",
    "<img src=\"support_files/images/pandas/pandas_grade_df.png\" width='200'>\n",
    "    \n",
    "or a `DataFrame` with Courses offered by Departments in different schools:\n",
    "\n",
    "<img src=\"support_files/images/pandas/pandas_departments_df.png\" width='500'>\n",
    "    \n",
    "or a `DataFrame` of Professors and the Courses they teach\n",
    "    \n",
    "<img src=\"support_files/images/pandas/pandas_professors.png\" width='500'>\n",
    "    \n",
    "   \n",
    "\n",
    "The main purpose of `pandas` and the `DataFrame` object is to allow us to ask questions across multiple sets of relations.  \n",
    "\n",
    "    \n",
    "<ul>\n",
    "    <li>What is the average score of students of course Y from professor X (who may have taught at different institutions….)?</li>\n",
    "    <li>What is the average number of students at school X from State Y?</li>\n",
    "    <li>What is the distribution of grades from students in Biology whose home town is Y?</li>\n",
    "</ul>\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "`DataFrames` have powerful tools like `merge` to combine information from multiple `DataFrame`s that allow you to ask these kinds of questions quickly and easily.\n",
    "    \n",
    "Let's get started!  \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='why_use_pandas'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h2>Why Use Pandas</h2>\n",
    "    \n",
    "**Annotated Data is Powerful!**\n",
    "\n",
    "Because pandas combines data labels with values it facilitites easy:\n",
    "* dataset exploration\n",
    "* dataset visualization\n",
    "* basic statistical analysis    \n",
    "\n",
    "<br/>\n",
    "\n",
    "**Data manipulation is easy!**\n",
    "\n",
    "Pandas takes the functionality of slicing & dicing data and layers in many other helpful features that help with:\n",
    "* cleaning data\n",
    "    * Column headers are descriptive not numerical.\n",
    "    * Columns hold single variables.\n",
    "    * Variables are stored in either rows or columns, not both.\n",
    "    * handling missing or invalid values\n",
    "* data wrangling\n",
    "    * getting the data into a structure that facilitates your analysis\n",
    "* easily loading and saving data\n",
    "    * load many formats of data and save in many formats\n",
    "\n",
    "\n",
    "<br/>\n",
    "    \n",
    "**High Level Data manipulation**\n",
    "\n",
    "Pandas supports vectorized mathematical operations which optimizes computation performance and execution speed. Additionally the 2D labeled tabular structure of a pandas dataframe allows other high level manipulations such as:\n",
    "* data grouping aggregation\n",
    "* table manipulations (transforming rows to columns &/or columns to rows)\n",
    "* Merging or Joinng multiple dataframes/tables</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px;\">\n",
    "    \n",
    "<center><h2>Table of Contents & Jumplinks</h2></center>\n",
    "<h4><a href='#introduction'>Introduction</a></h4>\n",
    "<li>Intro to Pandas and Dataframes\n",
    "<li>Intro Relational Data\n",
    "<li>why use pandas\n",
    "<li>resources & documentation\n",
    "\n",
    "<h4><a href='#imports'>Imports</a></h4>\n",
    "<h4><a href='#dataload'>Data Loading</a></h4>\n",
    "\n",
    "<h4><a href='#explore'>Explore the dataset & basic functionality</a></h4>\n",
    "<li>view the dataframe, how many rows & columns\n",
    "<li>view specifics about columns\n",
    "<li>get data types and unique entries\n",
    "<li>descriptive statistics\n",
    "\n",
    "<h4><a href='#dataselection'>Data Selection, slicing & dicing</a></h4>\n",
    "<li>select data by labels/names\n",
    "<li>select data by position\n",
    "<li>“views” vs copies of the data\n",
    "<li>conditional selection\n",
    "<li>multiple condition selection\n",
    "\n",
    "\n",
    "<h4><a href='#manipulate'>Table & Data Manipulation</a></h4>\n",
    "<li>add/create new columns\n",
    "<li>drop columns\n",
    "<li>sort values\n",
    "  \n",
    "<h4><a href='#plot'>Table transformation, aggregation & plotting</a></h4>\n",
    "<li>wide vs long tables\n",
    "<li>melt (transform wide to long df)\n",
    "<li>pivot (transform long to wide df)\n",
    "<li>cross tab (aggregate counts)\n",
    "<li>pivot_table (flexible aggregation)\n",
    "<li>groupby & agg\n",
    "\n",
    "<h4><a href='#table'>Create new tables, join tables, save tables</a></h4>\n",
    "<li>join & merge tables\n",
    "<li>create dataframe from scratch\n",
    "<li>saving dataframes \n",
    "    \n",
    "    \n",
    "<h4><a href='#bonus'>Bonus Material</a></h4>\n",
    "<li>split columns\n",
    "<li>rename columns\n",
    "<li> get column or dataframe values\n",
    "<li>select multiple items from a single column using a list\n",
    "<li>split strings in a column\n",
    "<li>adjust column data type to match assumptions</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2> Import Packages </h2> </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "**Library imports**    \n",
    "Here we'll load in the libraries we'll use to shape and explore the data</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import `pandas` and give it a short name `pd` since we will type it very frequently.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataload'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2> Load dataset </h2> \n",
    "\n",
    "Our first step is loading in the data from a CSV\n",
    "\n",
    "Pandas has great [tools for automatically interpretting data from many sources](https://pandas.pydata.org/docs/reference/io.html)\n",
    "    \n",
    "* pd.read_csv\n",
    "* pd.read_excel\n",
    "* pd.read_pickle\n",
    "* pd.read_json\n",
    "    \n",
    " we will use pd.read_csv</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_path = os.path.join('support_files', 'datasets', 'MessySuperStoreData.csv')\n",
    "df = pd.read_csv(csv_path, index_col='Row ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='explore'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2> Explore the dataset </h2> \n",
    "    \n",
    "<h3> Internal links </h3>\n",
    "\n",
    "**basic data exploration**\n",
    "\n",
    "* <a href='#df'>view dataframe \"preview\"</a>\n",
    "* <a href='#.head()'> view rows from beginning or end of dataframe (df.head, df.tail)</a>\n",
    "* <a href='#shape'>get dataframe shape and length(len, np.shape)</a>   \n",
    "* <a href='#.columns'>list all columns(.columns)</a>\n",
    "* <a href='#dtypes'>get column data types(.dtypes)</a>\n",
    "    \n",
    "**basic data visualization** \n",
    "    \n",
    "\n",
    "**descriptive statistics**\n",
    "* <a href='#describe'> get table level descriptive statistics</a>\n",
    "    \n",
    "    \n",
    "**Bonus Material**\n",
    "(found at end of notebook)\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='df'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>view the dataframe</h4>\n",
    "\n",
    "simply calling the dataframe ('df' or whatever you've named the dataframe) gives a preview view of the dataframe/table\n",
    "* shows the first 5 and last 5 rows of data\n",
    "* shows the first 10 and last 10 columns of data\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='.head()'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>View the first or last n rows</h4>\n",
    "\n",
    "**[.head()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html)**: shows the first n rows\n",
    "\n",
    "**[.tail()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html)**: shows the last n rows\n",
    "\n",
    "* <code>df.head()</code> and <code>df.tail()</code> shows 5 rows of data by default\n",
    "* adding a number <code>df.head(n)</code> adjusts the number of rows shown</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first 8 rows\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the last 7 rows\n",
    "df.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='shape'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>Get the shape and length of the dataframe</h4>\n",
    "\n",
    "beause pandas is built off of numpy, many familiar functions/methods work with DataFrames    \n",
    "\n",
    "* **[numpys shape function](https://numpy.org/doc/stable/reference/generated/numpy.shape.html)** can give the dimensions of a dataframe\n",
    "    * <code>df.shape</code> - returns (rows, columns)\n",
    "* **[len()](https://docs.python.org/3/library/functions.html#len)** - the built in python function will return the number of rows in a dataframe\n",
    "    * <code>len(df)</code></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='.columns'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "<h4>List Columns</h4>\n",
    "\n",
    "**[.columns](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.columns.html)** provides a list of the column labels for a dataframe\n",
    "    \n",
    "<code>df.columns</code></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try it out\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dtypes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "<h4>Show data from a single column</h4>\n",
    "\n",
    "Like retrieving a value from a dictionary, we can get the data for a single column by indexing with the column's name:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4> Get column or element data types</h4>\n",
    "\n",
    "* **[.dtypes](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html)** : lists the data type for all columns in a dataframe \n",
    "    * <code>df.dtypes</code>\n",
    "    \n",
    "* **type()** allows inspection of data type for a specific element (i.e. specific row & column)\n",
    "    * This can be helpful if the .dtypes function returns \"object\"\n",
    "    * <code>type(df['column'][row number])</code></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the built in type() function to get the first row of the \"Category\" column\n",
    "type(df[\"Category\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='unique'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4> get unique entries for a column</h4> \n",
    "\n",
    "**<code>[.unique](https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html#how-do-i-select-specific-columns-from-a-dataframe)</code>**\n",
    "\n",
    "\n",
    "<code>df['column_name'].unique()</code>   returns an array of all unique entries</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique entries for the Country column\n",
    "\n",
    "df['Country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**STUDENT EXERCISES:** \n",
    "\n",
    "1) What are the unique values for the Market column?\n",
    "\n",
    "2) Identify the data type for the Product ID column\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>Plotting with Pandas!</h4>\n",
    "    \n",
    "Pandas has a set of plotting tools built into the library. You can quickly create visualizations(especially with grouped and aggregated data which we will get to later) using pandas built in plotting functions such as:\n",
    "    \n",
    "\n",
    "* **<code>[.plot](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html)</code>**\n",
    "    * example:\n",
    "        \n",
    "        df.plot(x = 'xcolumn', \n",
    "            y= 'ycolumn',\n",
    "            kind = \"box\",\n",
    "            xlabel= 'x value units',\n",
    "            ylabel = 'y value units')\n",
    "\n",
    "    \n",
    "* **<code>[.boxplot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.boxplot.html)</code>**\n",
    "    \n",
    "    \n",
    "**NOTE!** Pandas works especially well with the the seaborn plotting package. We won't cover this now because there's a whole data visualization tutorial later! \n",
    "     </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a boxplot of  profit by category\n",
    "\n",
    "df.boxplot(column=['Profit'], by=['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.plot(x='Country', y='Order ID', kind = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='describe'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>get descriptive statistics</h4> \n",
    "\n",
    "\n",
    "Descriptive statistic are summary statistics that quantitatively describes or summarizes features from a collection of information or dataset. This typically included things like sample size, measures of central tendency (mean, median, mode), measures of variability or dispersion (standard deviation, min, max, kurtosis, skewness)\n",
    "    \n",
    " \n",
    "**<code>[.describe()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)</code>** will return descriptive statistics for all quantitative columns of a dataframe \n",
    "\n",
    "<img src=\"support_files/images/pandas/pandas_describe.png\">  \n",
    "\n",
    "<code>df.describe()</code> \n",
    "\n",
    "For each numerical column the following descriptive statitsics are provided:\n",
    "* count\n",
    "* mean\n",
    "* standard deviation\n",
    "* minimum\n",
    "* 25, 50 & 75th percentiles\n",
    "* max </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>other built in summary statistic functions</h4> \n",
    "\n",
    "Pandas also provides a large set of summary functions that can operate on different kinds of pandas objects (dataframe columns, Series, Groupby etc.)\n",
    "\n",
    "* **<code>[.count()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.count.html?highlight=count#pandas.DataFrame.count)</code>**    \n",
    "* **<code>[.sum()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sum.html?highlight=sum#pandas.DataFrame.sum)</code>**\n",
    "* **<code>[.min()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.min.html?highlight=min#pandas.DataFrame.min)</code>**\n",
    "* **<code>[.max()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.max.html?highlight=max#pandas.DataFrame.max)</code>**\n",
    "* **<code>[.mean()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html?highlight=mean#pandas.DataFrame.mean)</code>**\n",
    "* **<code>[.median()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.median.html?highlight=median#pandas.DataFrame.median)</code>**\n",
    "* **<code>[.var()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.var.html?highlight=var#pandas.DataFrame.var)</code>**\n",
    "* **<code>[.std()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.std.html?highlight=std#pandas.DataFrame.std)</code>**\n",
    "    \n",
    "These functions become especially useful in the next section where there might be some specific selection of  data you want to analyze </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do a very quick demonstration of how this works\n",
    "# here we get the mean discount for the entire discount column\n",
    "df[\"Discount\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**STUDENT EXERCISE:** \n",
    "\n",
    "What is the maximum value in the Shipping Cost column?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataselection'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2> Data Selection, Slicing & Dicing </h2>\n",
    "\n",
    "<h3> Internal Links </h3>\n",
    "    \n",
    "**basic data selection & filtering**\n",
    "* <a href='#column_selection'>column selection</a>\n",
    "* <a href='#view_vs_copy'>'view' of data vs a copy</a>    \n",
    "* <a href='#loc'>select data by labels/names</a>\n",
    "* <a href='#row_number_vs_index'>a note on row number vs index</a>\n",
    "* <a href='#iloc'>select data by integer Index/position</a>\n",
    "   \n",
    "**advanced data selection**\n",
    "* <a href='#conditionalselection'>select data for a given condition or threshold</a>\n",
    "* <a href='#conditionalselectionandreturn'>return subset of data for a given condition or threshold</a>\n",
    "* <a href='#multicondition'>select data based on multiple conditions or thresholds</a>\n",
    "  \n",
    " \n",
    "**Bonus Material**\n",
    "(found at end of notebook)\n",
    "* <a href='#multioptionlist'> multiple condition options using a list</a>    </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='column_selection'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>Column Selection</h4>\n",
    "\n",
    "**[column selection](https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html#how-do-i-select-specific-columns-from-a-dataframe)**\n",
    "    \n",
    "<img src=\"support_files/images/pandas/pandas_select_columns.png\">  \n",
    "\n",
    "to view a single single column\n",
    "* <code>df['column_name']</code>    (returns a pandas Series object, which is similar to a 1D array or list)\n",
    "\n",
    "~ OR ~\n",
    "* <code>df[['column_name']]</code>     (returns a DataFrame)\n",
    "\n",
    "multiple columns:\n",
    "* <code>df[['column_1', 'columns_2']]</code></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Category column as a pd.series\n",
    "\n",
    "df[\"Category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Category and Customer ID columns \n",
    "\n",
    "df[[\"Category\", \"Customer ID\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='view_vs_copy'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>Views vs copies</h4>\n",
    "\n",
    "We often want to work with only a subset of a dataframe. For that purpose, we can  select only those rows or columns that we need and leave the rest.\n",
    "    \n",
    "Building off of our knowledge of views vs copies that we learned with our numpy tutorial, when we subset an array the result is not always a new array; sometimes what numpy returns is a view of the data in the original array.\n",
    "Since pandas Series and DataFrames are backed by numpy arrays, it will probably come as no surprise that something similar sometimes happens in pandas. Unfortunately, while this behavior is relatively straightforward in numpy, in pandas there’s just no getting around the fact that it’s a hot mess.\n",
    "    \n",
    "**The View/Copy Headache in pandas**: In numpy, the rules for when you get views and when you don’t are a little complicated, but they are consistent: certain behaviors (like simple indexing) will always return a view, and others (fancy indexing) will never return a view.\n",
    "    \n",
    "But in pandas, whether you get a view or not—and whether changes made to a view will propagate back to the original DataFrame—depends on the structure and data types in the original DataFrame\n",
    "    \n",
    "<img src=\"support_files/images/pandas/pandas_view_vs_copy_b.png\">  \n",
    "\n",
    "    \n",
    "**When to create a copy using <code>[.copy()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html)</code>**\n",
    "      \n",
    "**Creating copies** of dataframes can be especially useful when doing exploratory analysis on a dataframe where you want to keep the integrity of the original dataframe in case you make a mistake.\n",
    "    \n",
    "<code>new_df = df.copy()</code> makes a copy (by creating a new object) of this object’s indices and data. By default modifications to the data or indices of the copy will not be reflected in the original object but see the documentation and the parameter <code>deep</code> for more information\n",
    "    \n",
    "Note: Like all other variables, try to keep your dataframe naming descriptive and intuitive to read!(For example \"new_df\" would be a bad name)\n",
    "<img src=\"support_files/images/pandas/pandas_modify_view.png\" width='60%'>\n",
    "    \n",
    "<img src=\"support_files/images/pandas/pandas_modify_copy.png\" width='60%'>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>Select rows or columns using labels</h4>\n",
    "\n",
    "**<code>[.loc()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html)</code>** allows access to a group of rows and columns by label(s) or a boolean array.\n",
    "\n",
    "**select rows:** \n",
    "* <code>df.loc['index']</code>\n",
    "    * hint: similar to column selection described above, for row selection using df.loc[ ] returns a series where df.loc[[ ]] returns a dataframe\n",
    "\n",
    "\n",
    "**select row and column:**\n",
    "* <code>df.loc['index', 'column']</code> </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows where the index is IN-2014-28967\n",
    "\n",
    "df.loc[\"IN-2014-28967\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index:ZI-2014-48372 and column'Country'\n",
    "df.loc[\"ZI-2014-48372\",'Country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='iloc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>Select rows and columns by position</h4>\n",
    "    \n",
    "**[.iloc()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html)** allows positional selection ie row number, column number. \n",
    "\n",
    "(Note that the same slicing notation that we saw with numpy arrays works with `iloc`.)\n",
    "    \n",
    "Example: <code>df.iloc([row(s) number, column(s) number])</code>\n",
    "\n",
    "Examples: \n",
    "* select all rows and all columns\n",
    "    * <code>df.iloc[:,:]</code> \n",
    "* select first 5 rows and all columns\n",
    "    * <code>df.iloc[0:4, :]</code> \n",
    "* select all rows and last 5 columns\n",
    "    * <code>.iloc[:,-5:]</code></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first 9 rows and all columns\n",
    "df.iloc[:9,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all rows and last 4 columns \n",
    "df.iloc[:,-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conditionalselection'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "\n",
    "<h4>Select data given a specific threshold or condition</h4>\n",
    "\n",
    "You can conditionally select data using **[.loc[ ]](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html)** or **[.query()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html)** or directly on the dataframe. Each of these utilize boolean masking. \n",
    "     \n",
    "<code>.loc</code>\n",
    "* <code>df.loc[df['column'] > 7]</code>\n",
    "* <code>df.loc[df['column'] == 'string']</code>\n",
    "    * Pros: explicit, can be easier to read for those who already know python\n",
    "    * cons: more verbose than query\n",
    "    \n",
    "----\n",
    "<code>.query()</code>:\n",
    "This method uses boolean expressions and may be easier & more intuitive for those who know sql or other database languages. \n",
    "\n",
    "Examples:\n",
    "* <code>df.query('column > 7')</code>\n",
    "* <code>df.query('column == string')</code>\n",
    "    * Pros: can be easier for those who know sql or other database languages, less verbose\n",
    "    * cons: can be difficult for those that donn't know sql, doesn't hand column names that contain spaces very well   </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .loc to select where Profit > 500\n",
    "df.loc[df['Profit'] > 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conditionalselectionandreturn'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "\n",
    "<h4>Return a subset of data given a specific threshold or condition</h4>\n",
    "\n",
    "You can also return specific columns after doing conditional selection data using **[<code>.loc</code>](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html)**. \n",
    "  \n",
    "single return column:\n",
    "* <code>df.loc[df['selection_column'] > 7, 'return_column']</code>\n",
    "\n",
    "multiple return columns (provide columns as a list):\n",
    "* <code>df.loc[df['selection_column'] > 7, ['return_column1', 'return_column2']]</code>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Category and Sub-Category where profit is above 500\n",
    "\n",
    "df.loc[df[\"Profit\"] > 500, [\"Category\", \"Sub-Category\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multicondition'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "\n",
    "**Multiple condition selection**\n",
    "\n",
    "You may wish to select rows or columns where multiple conditions are met. You can combine conditions with <code>.loc</code> and like in numpy you will utilize <code>&</code> and <code>|</code> \n",
    "\n",
    "example:\n",
    "<code>df.loc[(df['column1']=='string') & (df['column2'] > threshold)]</code>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return all entries where Profit is greater than 900 and the Sub-Category is \"Bookcases\"\n",
    "# the & means both conditions must be met\n",
    "\n",
    "df.loc[(df['Sub-Category']==\"Bookcases\") & (df['Profit'] >900)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return all entries where the Country is \"Australia\" or the Country is \"Zambia\"\n",
    "# the | means at least one condition must be met\n",
    "\n",
    "df.loc[(df['Country']==\"Australia\") | (df['Country']==\"Zambia\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**STUDENT EXERCISES:** \n",
    "\n",
    "1) Select Row ID \"AG-2014-50983\" and all columns\n",
    "\n",
    "2) Get the mean profit when the Category is furniture\n",
    "    \n",
    "3) Return the dataframe where \"Profit\" is negative and \"Market\" is 'EU'</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='manipulate'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2> Data & Table Manipulation </h2>\n",
    "    \n",
    "<h3> Internal links </h3>\n",
    "  \n",
    "* <a href='#addcolumns'> add/create new columns</a>\n",
    "* <a href='#dropcolumns'>drop unneccesary or redundant columns</a>\n",
    "* <a href='#dropna'>drop nan, NULL entries</a>\n",
    "* <a href='#sort_values'>sort the whole dataframe based on one column's values </a>\n",
    "    \n",
    "\n",
    "**Bonus Material**\n",
    "(found at end of notebook)\n",
    "* <a href='#split'> split single string column into two colums</a>    \n",
    "* <a href='#rename'> rename columns</a>\n",
    "* <a href='#changetype'>adjust column data type to match assumptions</a></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a new dataframe for this next set of examples\n",
    "# use .loc[] to select the united states as the country and .copy() to ensure \n",
    "# it's a new object and not altering our base dataframe\n",
    "\n",
    "USA_df = df.loc[df[\"Country\"]==\"United States\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='addcolumns'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>Add new columns</h4>\n",
    "    \n",
    "Frequently you'll want to add **[new columns](https://pandas.pydata.org/docs/getting_started/intro_tutorials/05_add_columns.html)**. There are multiple ways to do this! \n",
    "\n",
    "<img src=\"support_files/images/pandas/pandas_make_new_columns.png\">    \n",
    "to add already computed data:\n",
    "* <code>df['new_column_name'] = already_computed_data\n",
    "    \n",
    "You can also calculate new columns based on currently existing columns: \n",
    "* <code>df['AB_SUM'] = df['A'] + df['B']</code>\n",
    "* <code>df['Volume'] = df['Length'] * df['Height'] * df['Depth']</code>\n",
    "    \n",
    "note: newly created columns are always added to the end of the dataframe    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a great example of this in the next section!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dropcolumns'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "    \n",
    "<h4>Drop specific columns & rows using</h4> \n",
    "    \n",
    "You can easily drop rows or columns using **<code>[.drop()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html)</code>**\n",
    "\n",
    "There are many reasons you may wish to drop columns from your dataframe. Here are a few examples: \n",
    "* irrlevant to the analysis you are going to do\n",
    "* out of date\n",
    "* redundant information\n",
    "* non-analyzable due to high rates of Nan or empty entries\n",
    "    \n",
    "drop columns:    \n",
    "* <code>df = df.drop(columns=['column1', 'columns2'])</code>\n",
    "* <code>df = df.drop('column_name',axis=1)</code>\n",
    "\n",
    "drop rows:\n",
    "* <code>df = df.drop(index=('index1_string, 'index2_string'))</code>   \n",
    "* <code>df = df.drop([row, row])</code></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets drop the 'Category (OLD)'column \n",
    " \n",
    "USA_df.drop(columns=['Category (OLD)'], inplace=True)\n",
    "\n",
    "# check the results in the dataframe columns list\n",
    "USA_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "    \n",
    "<h4>Modifying data inplace</h4> \n",
    "\n",
    "**<code>[inplace](https://towardsdatascience.com/why-you-should-probably-never-use-pandas-inplace-true-9f9f211849e4#:~:text=Using%20the%20inplace%3DTrue%20keyword,which%20you%20apply%20it%20to.)</code>** is a parameter accepted by a number of pandas methods which affects the behaviour of how the method runs.\n",
    "Some examples of where you might commonly see this keyword are the methods(non-exhaustive): \n",
    "* <code>[.drop()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)</code>\n",
    "* <code>[.fillna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html)</code>\n",
    "* <code>[.replace()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html)</code>\n",
    "* <code>[.rename()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)</code>\n",
    "\n",
    "\n",
    "Using the <code>inplace=True</code> keyword in a pandas method changes the default behaviour such that the operation on the dataframe doesn’t return anything, it instead ‘modifies the underlying data’. It mutates the actual object which you apply it to.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dropna'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "   \n",
    "<h4>remove rows with missing values</h4>\n",
    "\n",
    "For columns of particular importance may wish to exclude rows that have missing values to do this we use \n",
    "**<code>[.dropna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)</code>**\n",
    "\n",
    "example: \n",
    "    <code>df.dropna(subset=['column'], inplace=bool)</code></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will also have an example of this in the next section!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sort_values'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>Sort the dataframe based on column values</h4>\n",
    "    \n",
    "**<code>[.sort_values()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html)</code>** to sort your dataframe by the the values of a particular column or columns. \n",
    "\n",
    "<code>df.sort_values(by=['column1', 'column2'], ascending = boolean, inplace= boolean)</code>\n",
    "    \n",
    "pro-tip: Sorting the values of your dataframe before plotting creates more interpretable plots. \n",
    "    \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets sort our USA_df by 'Segment', 'Category' and 'Sub-Category' \n",
    "# we will leave the underlying data unchanged by setting inpace to False\n",
    "\n",
    "USA_df.sort_values(by = ['Segment', 'Category', 'Sub-Category'], inplace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**STUDENT EXERCISES:** \n",
    "    \n",
    "1) create a 'profit per unit' column by dividing the profit column by quantity\n",
    "\n",
    "2) sort the table by profit per unit\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2> Table transformation, aggregation & Plotting </h2>\n",
    "    \n",
    "<h3> Internal links </h3>\n",
    "\n",
    "* <a href='#wide_vs_long'>Wide vs Long tables</a>\n",
    "* <a href='#melt'>transform to a wide dataframe using .melt</a>\n",
    "* <a href='#pivot'>transform to a long dataframe using .pivot</a>\n",
    "\n",
    "* <a href='#crosstab'> get a count of categorical variables with crosstab</a>   \n",
    "* <a href='#groupby'> aggregate data using .groupby and and get sum using .agg</a>\n",
    "* <a href='#pivot_table'> flexible aggregation of categorical variables with .pivot_tabe</a>    \n",
    "\n",
    "NOTE: while this tutorial uses pandas built in plotting functions there are many better packages for plotting, the [Seaborn](https://seaborn.pydata.org/) package workes especially well with pandas dataframe and other tabular style data</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wide_vs_long'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "    \n",
    "<h4>Wide vs Long dataframes</h4> \n",
    "\n",
    "<img src=\"support_files/images/pandas/pandas_wide_vs_long_df_b.png\" width=500/> \n",
    "\n",
    "**Wide**\n",
    "\n",
    "\n",
    "* methods for creating: <code>df.pivot()</code> and <code>pd.pivot_table(df)</code> can reshape a long dataframe into a wide dataframe\n",
    "    \n",
    "**Long**\n",
    " \n",
    "\n",
    "* methods for creating: <code>pd.melt(df)</code> can reshape a wide dataframe into a long dataframe\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>Resetting the index</h4>\n",
    "    \n",
    "In many of the table transformations, the process of transforming the data changes the index. If we wish to retain the index row we will want to reset the index before we do these transformations so it is saved in a regular column format. \n",
    "    \n",
    "This is easily achievable with **<code>[.reset_index()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html)<code>**. \n",
    "\n",
    " * Use <code>drop=True</code> if it's not necessary to maintain a column with the original indexes. </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USA_df.reset_index(inplace=True)\n",
    "\n",
    "USA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USA_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='melt'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>create a long dataframe with .melt()</h4>\n",
    "\n",
    "**<code>[.melt](https://pandas.pydata.org/docs/reference/api/pandas.melt.html)</code>** gathers columns into rows. \n",
    "\n",
    "It can be especially effective if you have several columns related columns containing many nans that would be better represented (and reduce the number of nans) if gathered into rows\n",
    "\n",
    "<img src=\"support_files/images/pandas/pandas_melt.png\">  \n",
    "        \n",
    "\n",
    "<code>df_melt = pd.melt(df, id_vars = [ columns ], value_vars= [ columns ], var_name = string, value_name = string)</code>\n",
    "    \n",
    "* <code>id_vars</code>: Column(s) to use as identifier variables\n",
    "    * columns you want to retain/ keep intact)\n",
    "* <code>value_vars</code>: Column(s) to unpivot. If not specified, uses all columns that are not set as id_vars.\n",
    "    * columns to transform\n",
    "* <code>var_name</code>:  Name to use for the ‘variable’ column. If None it uses frame.columns.name or ‘variable’.\n",
    "    * what are the columns you want to transform (are they cities? dates? something else?\n",
    "* <code>value_name</code>: Name to use for the ‘value’ column. \n",
    "    * what are the values of the columns you are going to transform (cost? population? temperature? etc?)\n",
    "    \n",
    "<img src=\"support_files/images/pandas/pandas_melt_examplec.png\" width ='60%'>\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "In our next example we want to transform our data from wide to long so we can concentrate NaNs to a single column to deal with removing them\n",
    "\n",
    "<img src=\"support_files/images/pandas/pandas_melt_practical_example.png\" width ='60%'></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may have noticed that there are many missing values in the columns \n",
    "# that contain each month, ie \"1/1/2014\". \n",
    "# We will gather these values from columns to rows, creating two new columns\n",
    "\n",
    "# the variables are the dates and the values represent sales\n",
    "\n",
    "\n",
    "# the column labels (var_name) all represent order date\n",
    "# the values(value_name) represent sales\n",
    "\n",
    "# try to keep your formatting legible by doing like so:\n",
    "columns_to_keep = ['Row ID','Order ID', 'Segment', 'Category', 'Sub-Category', 'Product Name',\n",
    "                   'Product ID', 'Country', 'Market', 'Region', 'City', 'State', \n",
    "                   'Quantity', 'Discount', 'Profit', 'Customer ID', 'Customer Name',\n",
    "                    'Order Priority', 'Postal Code', 'Ship Mode', 'Shipping Cost']\n",
    "\n",
    "\n",
    "columns_to_transform = ['10/1/2014', '7/1/2014', '11/1/2014', '9/1/2014', '1/1/2014',\n",
    "                        '12/1/2014', '8/1/2014', '5/1/2014', '3/1/2014', '4/1/2014',\n",
    "                        '2/1/2014', '6/1/2014']\n",
    "\n",
    "USA_long = pd.melt(USA_df,\n",
    "                   id_vars = columns_to_keep,\n",
    "                   value_vars = columns_to_transform,\n",
    "                   var_name = \"Order Date\",\n",
    "                   value_name = \"Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now see the new Dataframe, USA_long\n",
    "USA_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with empty values in the 'Sales' column\n",
    "usa_sales_long = USA_long.dropna(subset=['Sales'], inplace = False).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have our long dataframe\n",
    "# Lets create a new column cost of goods \"COGS\" \n",
    "# we can calculate the cost of goods by by subtracting the profits from the sales\n",
    "usa_sales_long['COGS'] = USA_long['Sales'] - USA_long['Profit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pivot'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>create a wide dataframe with .pivot()</h4>\n",
    "   \n",
    "**<code>[.pivot](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html)</code>** allows us to transform rows into columns\n",
    "    \n",
    "<img src=\"support_files/images/pandas/pandas_pivot.png\">  \n",
    "\n",
    "example: \n",
    "<code>df.pivot(columns = [ column(s) ])</code>\n",
    "\n",
    "Parameters:    \n",
    "\n",
    "* <code>columns</code>: Column to use to make new frame’s columns.\n",
    "* <code>index</code> (optional): Column to use to make new frame’s index. If None, uses existing index.\n",
    "* <code>values</code> (optional): Column(s) to use for populating new frame’s values. If not specified, all remaining columns will be used and the result will have hierarchically indexed columns.   \n",
    "\n",
    "<img src=\"support_files/images/pandas/pandas_pivot_b.png\" width ='550'> </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get just the 'state' and 'Category' columns and turn the 'Category' column into rows \n",
    "USA_COGS_wide = usa_sales_long.pivot(index = ['Row ID'],\n",
    "                                     columns='Order Date',\n",
    "                                     values = 'Sales')\n",
    "\n",
    "# view the resulting dataframe.\n",
    "USA_COGS_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**STUDENT EXERCISES:**\n",
    "    \n",
    "1) what are some types of plots or analysis that would be facilitated by having a wide form dataframe?\n",
    "    \n",
    "2) what about a long form dataframe? \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='crosstab'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4> Aggregate and Get Frequency Counts </h4>\n",
    "\n",
    " **<code>[.crosstab()](https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html)</code>** allows you to aggregate by category and get frequency counts. \n",
    "    \n",
    "Cross-tabulations or contingency tables are tables used to describe relationships between two categorical variables. The table displays the frequency distribution of the variables. This is a very easy built in function to use, but the downside is that it is not flexible. It only offers frequency counts. \n",
    "\n",
    "<code>x_tab = pd.crosstab(index = df[categorical column], columns=df[categorical column])</code>\n",
    "* <code>index</code> Values to group by in rows\n",
    "* <code>columns</code> Values to group by in columns</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example we want to be able to count number of orders\n",
    "# by order priority and shipping mode\n",
    "\n",
    "xtab = pd.crosstab(USA_long['Order Priority'], \n",
    "                   columns = USA_long['Ship Mode'])\n",
    "\n",
    "# view the results\n",
    "xtab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pivot_table'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>aggregate data using .pivot_table()</h4>\n",
    "\n",
    "**<code>[.pivot_table()](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html)</code>** allows us to construct quick aggregate tables using categorical variables. This is slightly more complicated than crosstab but it offers more flexibility in aggregator functions.\n",
    "    \n",
    "example: \n",
    "<code>pd.pivot_table(df, values = [ ], index = [ ], columns = [ ], aggfunct = )</code>\n",
    "    \n",
    "* <code>values</code>: The column to aggregate (if blank, will aggregate all numerical values)\n",
    "* <code>index</code>: The column or columns to group data by. A single column can be a string, while multiple columns should be a list of strings\n",
    "* <code>columns</code>: The column or columns to group data by. A single column can be a string, while multiple columns should be a list of strings\n",
    "* <code>aggfunc</code>: the type of aggregator function to use, you can use one or many\n",
    "    * examples: 'count', 'Mean': np.mean, 'Sigma': np.std</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see how this works lets make something similar to our crosstab with counts! \n",
    "\n",
    "# Lets use Order ID as our values because it's unique\n",
    "# set our index to \"Order Priority\"\n",
    "# use \"Ship Mode\" as our columns\n",
    "# and lets count as our aggregate function to count how many \n",
    "# Order IDs there are for each order priorty and shipping mode\n",
    "\n",
    "pd.pivot_table(USA_long,\n",
    "               values  = ['Order ID'],\n",
    "               index   = ['Order Priority'],\n",
    "               columns = ['Ship Mode'],\n",
    "               aggfunc = ['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do the same thing but with columns that contain values rather than categories. \n",
    "# Lets use Sales as our values, and Order Priority and Segment as our index and columns\n",
    "# we can also get sum and mean at the same time!\n",
    "\n",
    "pd.pivot_table(USA_long, \n",
    "               values  = ['Sales'],\n",
    "               index   = ['Order Priority'],\n",
    "               columns = ['Segment'],\n",
    "               aggfunc = [np.sum, np.mean])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='groupby'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>aggregate data using .groupby()</h4>\n",
    "\n",
    "**<code>[.groupby()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html</code>)** allows you to group a dataframe using a mapper or by a Series of columns. A groupby operation involves some combination of splitting the object, applying a function, and combining the results. This can be used to group large amounts of data and compute operations on these groups.\n",
    "\n",
    "\n",
    "<code> grouped_object = df.groupby(by =[columns])</code>\n",
    "\n",
    "<img src=\"support_files/images/pandas/pandas_groupby_b.png\" width ='70%'>  \n",
    "    \n",
    "You can then run analytics or further aggregations on each of the groups in your groupby object. You can use many of the descriptive statistics functions we talked about early in the notebook or **<code>[.agg()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html)</code>** will also compute aggregation on the grouped object.  Example aggregators: min, max, sum, mean, median etc. \n",
    "\n",
    "* <code>grouped_object.max()</code>\n",
    "* <code>grouped_object.agg([aggregator])</code>\n",
    "\n",
    "\n",
    "<img src=\"support_files/images/pandas/pandas_groupby_c.png\" width ='70%'>\n",
    "    \n",
    "\n",
    "**Groupby \"pipeline\":**<br>\n",
    "<img src=\"support_files/images/pandas/pandas_groupby_split_apply_combine.png\">      \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This last is gonna be slightly more complicated! \n",
    "\n",
    "# Now lets subset the dataframe to just \"Region\" and \"COGS\"\n",
    "COGS_df = usa_sales_long[['Region', 'COGS']]\n",
    "\n",
    "# Groupby Region and get the sum for each region\n",
    "region_agg = COGS_df.groupby(by = 'Region').agg(['sum'])\n",
    "\n",
    "# Lets view the output dataframe\n",
    "region_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**STUDENT EXERCISES:** \n",
    "<p>1) What State has the highest Profit in the US?\n",
    "<p>2) Which Customer had the 3rd highest total Sales?\n",
    "\n",
    "HINT: use the index to easily access sorted data by location</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='table'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h2> Creating, Joining and Saving dataframes </h2>\n",
    "    \n",
    "<h3> Internal links </h3>\n",
    "\n",
    "**<a href='#create_table'> Creating DataFrames from Scratch:</a>** \n",
    "* <a href='#table_from_array'> from an array</a>\n",
    "* <a href='#table_from_lists'> from a lists</a>\n",
    "* <a href='#table_from_dict'> from a dictionary</a>\n",
    " \n",
    "\n",
    "**Combining DataFrames**\n",
    "* <a href='#concat'>append tables with the same structure using .concat</a>   \n",
    "* <a href='#reset_index'>resetting an index</a> \n",
    "* <a href='#merge_df'> merging dataFrames</a>\n",
    "* <a href='#merge_left_right'> left and right merges</a>\n",
    "* <a href='#merge_inner_outer'> inner and outer merges</a>\n",
    "\n",
    "**Saving DataFrames**\n",
    "* <a href='#save_df'>save to excel</a>\n",
    "* <a href='#save_df'>save to .csv</a> </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create_table'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>Creating a DataFrame</h4>\n",
    "\n",
    "You can create dataframes from scratch by using **<code>[pd.DataFrame()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)</code>**\n",
    "\n",
    "    \n",
    "Because dataFrames are tabular, your data will need column names. This usually means that creating a dataframe from scratch will require some combination of using arrays, lists or dictionaries. </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='table_from_array'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "**Create a dataframe from a numpy array**\n",
    "\n",
    "When creating a dataframe from an array it's important that you know what each dimension of your array represents. Lists and dictionaries are a little more self-documenting in that way, but using arrays can be very efficient. \n",
    "\n",
    "You must always provide the correct number of column labels to match your array dimensions \n",
    "* <code>pd.DataFrame(data_array, columns=['column_1','column_2'...])</code>\n",
    "    \n",
    "     \n",
    "Note: for this example we will have to create a numpy array (using <code>numpy.random.rand</code>), however in the real world you would already have your array that you'd like to turn into a dataframe.</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first create the array using numpy random.rand(rows,columns)\n",
    "data_array = np.random.rand(25,3) \n",
    "data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the dataframe, assigning data first and then the columns\n",
    "# our array is 25 rows x 3 columns so we must provide 3 column labels\n",
    "array_df = pd.DataFrame(data_array, columns=['column_1','column_2','column_3'])\n",
    "\n",
    "#view the dataframe\n",
    "array_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='table_from_lists'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "**dataframe from lists**\n",
    "\n",
    "You can easily make a dataframe from multiple lists and a dictionary. \n",
    "* Each list represents a column of data.\n",
    "* dictionary keys represent column names\n",
    "* dictionary values are the lists that contain all the data/rows  \n",
    "    \n",
    "Note: all lists must be the same length! </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "For the lists and dictionaries examples we will make a dataframe of adoptable pets! </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make the lists, we will have 4 entries for each list\n",
    "name = ['Oreo','Squid','Mrs Noris', 'Dazzler']\n",
    "age_months = [5, 18, 12, 9]\n",
    "\n",
    "\n",
    "# then assign the lists to appropriate column names using dictionary keys\n",
    "dict_of_lists = {'name': name,\n",
    "                 'age_months': age_months}\n",
    "\n",
    "# finally create a dataframe using the dictionary\n",
    "dict_df1 = pd.DataFrame(dict_of_lists)\n",
    "dict_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to make a dataframe using lists and dictionaries is to do the dictionary\n",
    "# assignment within the dataframe creation call. This just cuts out a middle step\n",
    "\n",
    "names = ['Cheddar', 'Zuko']\n",
    "age_months = [7, 21]\n",
    "\n",
    "dict_df2 = pd.DataFrame({'name':names,\n",
    "                         'age_months': age_months})\n",
    "dict_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='table_from_dict'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "**dataframe from list of dictionaries**\n",
    "\n",
    "You can also create a single list that contains multiple dictionaries. \n",
    "* each dictionary represents a row\n",
    "* each key represents a column. \n",
    " \n",
    "note: you must use the exact same keys in all dictionaries using this method. </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = [\n",
    "    {'name': 'Oreo',      'species': 'dog'},\n",
    "    {'name': 'Dazzler',   'species': 'cat'},\n",
    "    {'name': 'Templeton', 'species': 'rat'},\n",
    "]\n",
    "\n",
    "list_df = pd.DataFrame(list_of_dicts)\n",
    "list_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='concat'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>Append dataframes using concat</h4>\n",
    "\n",
    "you can append one dataframe to another if they have the same structure(i.e. same columns OR same indexes) using **<code>[.concat()](https://pandas.pydata.org/docs/reference/api/pandas.concat.html)</code>**\n",
    "\n",
    "concatenate rows:\n",
    "    <code>pd.concat([df1,df2])</code>\n",
    "  \n",
    "<img src=\"support_files/images/pandas/pandas_concat_rows.png\">    \n",
    "\n",
    "concatenate columns:\n",
    "    <code>pd.concat([df1,df2], axis=1)</code>\n",
    "\n",
    "<img src=\"support_files/images/pandas/pandas_concat_columns.png\"> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_df1 and dict_df2 have the same structure without redundancy\n",
    "# so they're good candidates for concatenation. \n",
    "\n",
    "pd.concat([dict_df1, dict_df2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try concatinating again but resetting the index while we do so\n",
    "\n",
    "pd.concat([dict_df1, dict_df2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='merge_df'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>Merging DataFrames</h4>\n",
    "    \n",
    "Needing to merge or join dataframes is a very common occurance in data analysis. Frequently one table contains a specific type of data while another table contains some other data, and you wish to combine that information. \n",
    "\n",
    "There are several different ways to merge DataFrames. The most common way is using **<code>[.merge()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html)</code>**\n",
    "\n",
    "Important function arguments:\n",
    "* <code>how</code> determines the way the dataframes are merged. There are 4 basic options: \n",
    "    * <code>'left'</code> & <code>'right'</code>\n",
    "    * <code>'inner'</code>(default) & <code>'outer'</code>\n",
    "    \n",
    "* <code>on</code> argument identifies which column(s) are common across both dataframes and should be used as the index to merge the dataframes on\n",
    "    * in the example images below 'x1' is the common column that would be used\n",
    "        * <code>on ='x1'</code></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='merge_left_right'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>Left and Right merges</h4>\n",
    "\n",
    "For <code>'left'</code> and <code>'right'</code> merges, the order that you list the dataframes in the <code>.merge()</code> function matters. The first dataframe listed is the 'left' dataframe and the second is the 'right' dataframe.\n",
    "\n",
    "* left merge:\n",
    "    * Joins matching rows from df_right to df_left, retaining all the information from the df_left.\n",
    "    * <code>left_merge_df = pd.merge(df_left, df_right, how='left', on='x1')</code>\n",
    "  \n",
    "<img src=\"support_files/images/pandas/pandas_join_left.png\">    \n",
    "\n",
    "* right merge example: \n",
    "    * Joins matching rows from df_left to df_right, retaining all the information from the df_right\n",
    "    * <code>right_merge_df = pd.merge(left_df, right_df, how='right', on='x1')</code>\n",
    "\n",
    "<img src=\"support_files/images/pandas/pandas_join_right.png\"> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do a LEFT join \n",
    "# dict_df1 which contains information on animal 'name' and 'age_months'\n",
    "# list_df contains 'name' and 'species'\n",
    "\n",
    "pd.merge(dict_df1, list_df, how = 'left', on ='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a right join with the same dataframes! \n",
    "\n",
    "pd.merge(dict_df1, list_df, how = 'right', on ='name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='merge_inner_outer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>Inner and Outer Merges</h4>\n",
    "\n",
    "For <code>'inner'</code> and <code>'outer'</code> merges, the order of the dataframes does not matter. Instead the inner and outer merges are based on what is common between both dataframes.\n",
    "\n",
    "* inner merge:\n",
    "    * Join data and retains only rows found in both dataframes.\n",
    "    * <code>inner_merge_df = pd.merge(df1, df2, how='inner', on='x1')</code>\n",
    "  \n",
    "<img src=\"support_files/images/pandas/pandas_join_inner.png\">    \n",
    "\n",
    "* outer merge: \n",
    "    * Joins dataframes and retains all values, all rows.\n",
    "    * <code>outer_merge_df = pd.merge(df1, df2, how='outer', on='x1')</code>\n",
    "\n",
    "<img src=\"support_files/images/pandas/pandas_join_outer.png\"> </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try an outer merge with those same dataframes\n",
    "\n",
    "pd.merge(dict_df1, list_df, how = 'outer', on ='name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4> Merging with Indexes</h4>\n",
    "    \n",
    "You may have two tables that you'd like to merge where the index of one dataframe is a column in another dataframe. \n",
    "    \n",
    "<img src=\"support_files/images/pandas/pandas_index_merge.png\">  \n",
    "\n",
    "<code>df1.merge(df2, left_on = \"x3\", right_index = True)</code>    \n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "<code>left_on</code> label or list, or array-like\n",
    "Column or index level names to join on in the left DataFrame. Can also be an array or list of arrays of the length of the left DataFrame. These arrays are treated as if they are columns.\n",
    "\n",
    "<code>right_on</code> label or list, or array-like\n",
    "Column or index level names to join on in the right DataFrame. Can also be an array or list of arrays of the length of the right DataFrame. These arrays are treated as if they are columns.\n",
    "\n",
    "<code>left_index</code> bool, default False\n",
    "Use the index from the left DataFrame as the join key(s). If it is a MultiIndex, the number of keys in the other DataFrame (either the index or a number of columns) must match the number of levels.\n",
    "\n",
    "<code>right_index</code> bool, default False\n",
    "Use the index from the right DataFrame as the join key. Same caveats as left_index.\n",
    "\n",
    "NOTE: If you have other columns in common besides the merging column/index these will appear twice in your new dataframe! </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='save_df'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "**Saving dataframes**\n",
    "\n",
    "Just like loading dataframes, there are many different formats that you can save a dataframe to. We will just show you .csv and .xls but to see a complete list please check out the [input/output documentation here](https://pandas.pydata.org/docs/reference/io.html):\n",
    "\n",
    "* [.to_csv()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)\n",
    "    * <code>df.to_csv('df_save_name.csv')</code>\n",
    "\n",
    "* [.to_excel()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html#pandas.DataFrame.to_excel)\n",
    "    * <code>df.to_excel('df_save_name.xlsx')</code>\n",
    "\n",
    "    \n",
    "by default the save functions will save to your working directory. You must specify a path if you wish to save your dataframe elsewhere.\n",
    "    \n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**STUDENT EXERCISES:** \n",
    "\n",
    "1) Read in population data from the csv file and show the columns (find file in: support_files/datasets/population_by_country_2020.csv).\n",
    "\n",
    "2) Perform a left merge on the original dataframe (df) and new population population dataframe, using \"Country\" column, print columns to confirm merge\n",
    "\n",
    "3) Return the merged dataframe from \"Country\" with the highest population, first 10 rows\n",
    "\n",
    "This country population dataset was provided mostly as an example for you to trying merging two diffeferent datasets. But feel free to consider interesting questions and corresponding plots to investigate this merged data. For example, is there a difference in categories of items sold in high vs low population countries?</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bonus'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2> Bonus Material! </h2>\n",
    "    \n",
    "<h3> Internal links </h3>\n",
    "    \n",
    "    \n",
    "A large portion of this bonus material is useful when cleaning up your initial dataset.\n",
    "  \n",
    "* <a href='#values'> get column or dataframe values</a>    \n",
    "* <a href='#multioptionlist'>select multiple items from a single column using a list</a>\n",
    "* <a href='#split'>split strings in a column</a>\n",
    "* <a href='#rename'>rename a column</a>\n",
    "* <a href='#changetype'>adjust column data type to match assumptions</a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='values'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h4>get table or column values</h4>\n",
    "    \n",
    "* to get the values of a specific column in an array use **<code>[.values](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.values.html)</code>**\n",
    "    * returns an array of values where NaNs are maintained\n",
    "* to get turn the whole dataframe into an array use **<code>[.to_numpy](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy)</code>**</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .values to get the values of the \"Postal Code\" column\n",
    "df[\"Postal Code\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .to_numpy to get the dataframe as a numpy array\n",
    "df.to_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multioptionlist'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "\n",
    "**Multiple conditions using a list**\n",
    "\n",
    "If you have multiple conditions or options for a single column using **<code>[.isin()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html)</code>** may be particularly helpful. \n",
    "\n",
    "Using isin lets you define a list values to check for. You can either define this within the .loc statement or outside it if the list is particularly long. \n",
    "    \n",
    "defined inside .loc statement:\n",
    "\n",
    "    subset_df = df.loc[df['column'].isin(['string1','string2'])]\n",
    "\n",
    "defined outside .loc statement:\n",
    "\n",
    "    values_list = ['string1','string2', 'string3', 'string4']\n",
    "    subset_df = df.loc[df['column'].isin(values_list)] </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the dataframe where the Country is either \n",
    "# 'Austria', 'South Korea', 'Uganda', 'Thailand', 'Nicaragua', or 'Slovakia'\n",
    "\n",
    "countries_list = ['Austria', 'South Korea', 'Uganda', 'Thailand', 'Nicaragua','Slovakia']\n",
    "\n",
    "df.loc[df['Country'].isin(countries_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='split'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "\n",
    "<h3>Split a string column</h3>\n",
    "    \n",
    "We will use **[.str.split()](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html)** to split a column that contains a string into two separate columns. \n",
    "\n",
    "<code>split_df = df['column name'].str.split(separator, Limit number of splits in output, list output in separate columns)</code></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Customer Name\" column into: \"First Name\" and \"Last Name\"\n",
    "\n",
    "# first we will look at the column to see what the separator is\n",
    "df[[\"Customer Name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using , as the separator we will create a new new_string_df containing those two columns\n",
    "split_string_df = df[\"Customer Name\"].str.split(\" \", n = 1, expand = True)\n",
    "\n",
    "# view the results\n",
    "split_string_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rename'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    "  \n",
    "<h4>rename columns</h4>\n",
    "    \n",
    "There may be times when you wish to rename columns or indexes, to make them more descriptive or to fix typos or remove special characters. **<code>[.rename()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)</code>** will do this. \n",
    "\n",
    "* rename indexes/rows: <code>df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})</code>\n",
    "* rename columns: <code>df.rename(columns={\"A\": \"a\", \"B\": \"b\", \"C\": \"c\"})</code></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our split_string_df we created above, 0 and 1 are not very descriptive column names\n",
    "# lets change their names to be more meaningful. \n",
    "# rename columns 0, 1 to \"Cust First Name\" and \"Cust Last Name\", here we will set inplace=True because 0 and 1 are not meaningful\n",
    "\n",
    "split_string_df.rename(columns={0:\"Cust First Name\", 1:\"Cust Last Name\"}, inplace=True)\n",
    "\n",
    "# view the updated dataframe\n",
    "split_string_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets add the \"already computed\" columns from the split_string_df to our USA_df\n",
    "\n",
    "# add the new columns\n",
    "df[\"Cust First Name\"]= split_string_df[\"Cust First Name\"]\n",
    "df[\"Cust Last Name\"]= split_string_df[\"Cust Last Name\"]\n",
    "\n",
    "# view the updated dataframe columns to make sure your newly added columns are there \n",
    "# hint: they will be added at the end of the columns list\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='changetype'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; padding-left: 10px; background:#e6e6e6\">\n",
    " \n",
    "<h4>change column datatype with</h4>\n",
    " \n",
    "**<code>[.astype()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html)</code>** allows you to recast the datatype of an entire column. This is especially helpful as some columns may be ready into the dataframe as the incorrect type. \n",
    "\n",
    "<code>df['column'] = df['column'].astype(desired_type)</code></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the column \"Postal Code\" is currently a float when it should be an int.\n",
    "# Lets use our USA_df for this example\n",
    "\n",
    "USA_df['Postal Code'] = USA_df['Postal Code'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pandas_resources'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "\n",
    "**Documentation & Resources**\n",
    "    \n",
    "This introduction will only just scratch the surface of Pandas functionality. For more information, check out the [full documentation](https://pandas.pydata.org/docs/reference/index.html)\n",
    "    \n",
    "This [cheat-sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) is also highly recommended to print out and keep handy as a resource.\n",
    "<p>Or check out the <a href=\"http://pandas.pydata.org/pandas-docs/stable/10min.html\">'10 minutes to Pandas'</a> tutorial here (note: title may mischaracterize time investment).</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "78317d31f00423c19d7de96a53b10e98bbd020936ca21b1bcba5599b7b724f64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
