{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../resources/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">Neuropixels Dataset Exercises </h1> \n",
    "<h2 align=\"center\">Summer Workshop on the Dynamic Brain </h2> \n",
    "<h3 align=\"center\">Wednesday, August 28, 2019</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../resources/EphysObservatory/neuropixels.png\" height=\"250\" width=\"250\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n",
    "from allensdk.brain_observatory.ecephys import ecephys_session\n",
    "%matplotlib inline\n",
    "\n",
    "# fix slow autocomplete\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "platstring = platform.platform()\n",
    "\n",
    "if 'Darwin' in platstring:\n",
    "    # OS X \n",
    "    data_root = \"/Volumes/Brain2019/\"\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "elif ('amzn1' in platstring):\n",
    "    # then on AWS\n",
    "    data_root = \"/data/\"\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2019/\"\n",
    "\n",
    "manifest_path = os.path.join(data_root, \"dynamic-brain-workshop/visual_coding_neuropixels/2019/manifest.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 1: Recordings across visual areas</b> \n",
    "<br>\n",
    "Make raster plots for 20 units in each of the 6 visual areas ('VISp','VISl','VISal','VISrl','VISam','VISpm') for the first 5 minutes of the sessions.\n",
    "<ol>\n",
    "<li> Select a session that has data in all 6 areas\n",
    "<li> Loop over these 6 areas\n",
    "<li> Loop over 20 units per area, get their spike times, and plot them in a raster plot\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 2: ISI distributions</b>\n",
    "<ol>\n",
    "    <li>For a single unit, plot the inter-spike interval distribution with 1 ms bins. Show 2 graphs with different x-limits: (0, 20 ms) and (0, 200 ms).\n",
    "    \n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "  \n",
    "Hints: Use the function np.diff to compute the difference between adjacent spike times (i.e. the inter-spike interval). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 2 continued: ISI distributions</b>\n",
    "<ol>\n",
    "    <li>Get spike times for 50 units with highest SNR </li>\n",
    "    <li>Provided that the unit has at least 3000 spikes, plot ISI distribution for each unit (a single plot each).</li>\n",
    "    <li>How do the ISI distributions vary between cells?</li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "  \n",
    "Hints:  `plt.subplots(...sharex=True)` will help keep all your subplots on the same scale automatically so they can be easily compared.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 5: Explore responses to natural scenes</b> \n",
    "<ol>\n",
    "    <li>Construct a stim_table for natural scenes, and use `get_stimulus_parameter_values` to list the possible values for all stimulus parameters. How many different images are presented? What do you think frame=-1 is?</li>\n",
    "    <li>Use the presentationwise_spike_counts method to calculate the spike counts in 5 ms bins, for all presentations of a chosen image. Use a window extending one full stimulus presentation before and after the presentation of interest (showing three presentations total). Then take the mean across presentations to find the PSTH. \n",
    "    <li>Plot the histogram (as in step above) for all images separately.\n",
    "    <li>Plot the image that drives the largest response for this unit.\n",
    "    \n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 5 continued: Explore responses to natural scenes</b> \n",
    "<ol>\n",
    "    <li>Create a `conditionwise_spike_statistics` table for these stimuli.</li>\n",
    "    <li>Plot the mean Â± sem of the response to each image, add a dotted line (plt.axhline()) to represent the response to the blank sweep (frame=-1). Bonus: Use plt.axhspan() to shade the sem of the blanksweep. </li>\n",
    "\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 5 continued: Explore responses to natural scenes</b> \n",
    "Some neurons have broad responses to lots of images, others respond only to a single or few images. One way to quantify this type of selectivity is using the <b>lifetime sparseness</b> metric. A high value of this metric indicates high selectivity - a differential response to one or a few stimulus conditions over others. A low value of this metric indicates a similar response across all conditions.   \n",
    "\n",
    "<ol>\n",
    "    <li>Compute the lifetime sparseness for the unit you plotted above.</li>\n",
    "    <li>Extra credit: compute the lifetime sparseness for several units in your experiment. What's the range of values you see? Compare with the tuning plots you computed above for those neurons - make plots as the one directly above this and add the lifetime sparseness as a title.</li>\n",
    "\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 6: Population correlations and cross-correlograms of spiking activity</b>\n",
    "<br>\n",
    "The neural activity is often correlated between the neurons. The relationship between the activity of two units at different time lags is quantified by the cross-correlation. When the cross-correlation is plotted with respect to time lag, we call this a cross-correlogram.\n",
    "<br>\n",
    "We can also calculate a single correlation coefficient (at zero lag) for all pairs of recorded units, and visualize this using a matrix representation. In this exercise, you will compute the correlation matrix and compare it between different stimulus presentaitons.\n",
    "<ol>\n",
    "    <li>Correlations can be studied on many different timescales. Here we'll use a 10 ms timescale, so use `presentationwise_spike_counts` to create spike histograms for 10 ms time bins for both drifting gratings and spontaneous activity. Call the output 'histograms_drift' and 'histograms_spont'\n",
    "    <li>Compute the cross_correlograms for two arbitatrary units during spontaneous activity and during drifting gratings presentation. Make sure you are using the same duration for the two stimulis as different stimuli have different length of presentation. Use the `scipy.signal.correlate` function to calculate the cross-correlation. Plot these cross_correlograms. How do they look different?\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 6 continued: Population correlations and cross-correlograms of spiking activity</b>\n",
    "<br>\n",
    "The neural activity is often correlated between the neurons. The relationship between the activity of two units at different time lags is quantified by the cross-correlation. When the cross-correlation is plotted with respect to time lag, we call this a cross-correlogram.\n",
    "<br>\n",
    "We can also calculate a single correlation coefficient (at zero lag) for all pairs of recorded units, and visualize this using a matrix representation. In this exercise, you will compute the correlation matrix and compare it between different stimulus presentaitons.\n",
    "<ol>\n",
    "    <li>Compute the linear pearson correlation coefficients for all pairs of the first 100 units, and store them as a correlation matrix. Use `scipy.stats.pearsonr` function. Visualise the matrix using imshow() command. Hint: if the values are constant, it makes sense to assume the correlation to be zero. </li>\n",
    "    <li>Compare the correlation matrix structure for spontaneous actiivty and drifting gratings for the same units. Hint: to make it more clear, plot the correlations using log10(corr + 1) scaling.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 7: Spike waveform features</b> \n",
    "<br>Compute the spike duration for your selected list of units, and plot histogram of values.\n",
    "<ol>\n",
    "    <li>Concatenate waveforms in a matrix</li>\n",
    "    <li>Compute location of trough and peak using np.argmax() and np.argmin()</li>\n",
    "    <li>Compute difference between time of trough and peak</li>\n",
    "    <li>Plot histogram of spikes duration (time between trough and peak)</li>\n",
    "    <li>Bonus: construct a scatter plot comparing your results with the pre-calculated values in the units table, `session.units.waveform_duration`</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 8: Spike-field relationships</b> \n",
    "<br>\n",
    "The LFP is the product of the coordinated activity of a large number of cells localized near the probe, many more than those for which we have identified spikes. Thus, one way of understanding relationships between single neurons and the population is to look at relationships between spike times and the LFP. \n",
    "<br>\n",
    "Here we will calculate the spike-triggered average of the LFP signal. If a certain pattern is repeated in the LFP whenever the cell fires, the averaging will help to isolate this signal and average out the noise. \n",
    "<ol>\n",
    "    <li>Pick a unit, extract the LFP for the channel closest to it's peak channel, and select a subset of spikes to work with. (Working with the full dataset across channels and across all spiikes would take quite a while.) </li>\n",
    "    <li>For each spike time of the unit, pick out a fixed window of the LFP aligned around the spike time. </li>\n",
    "    <li>Average the windowed LFP signals to compute the spike-triggered average, and plot the results. Do you think this would look different if we had picked a channel further from the cell?</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 9: Instantaneous phase of oscillatory LFP signals</b> \n",
    "<br>\n",
    "Another way to analyze how an oscillatory signal varies with time is to extract its instantaneous amplitude using a mathematical tool called the Hilbert transform. The function `scipy.signal.hilbert` adds a second dimension to a signal (as a complex variable), such that the resulting *analytic signal* now has a well-defined nonzero amplitude and phase at every instant in time! (See http://www.rdgao.com/roemerhasit_Hilbert_Transform/ for a nice explanation.)\n",
    "<br>\n",
    "Note that these instantaneous amplitude and phase could be a starting point for more complex analysis of relationships between spike times and the LFP, or between LFP signals in different regions. We won't have time to get into that here!\n",
    "<ol>\n",
    "    <li>Working with a ~10 sec window of LFP from a single channel, find the peak frequency of the signal using the welsh periodogram.</li>\n",
    "    <li>Filter the signal using the Butterworth filter, using a window of +/- 2 Hz around the peak frequency.</li>\n",
    "    <li>Calculate the analytic signal from your filtered LFP </li>\n",
    "    <li>Use `np.abs` and `np.angle` to calculate the amplitude and phase of the signal. Visualize the filtered LFP along with its amplitude and phase.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Bonus! Exercise 10: Explore tuning curves for static gratings, using seaborn plotting tools.</b> \n",
    "<ol>\n",
    "    <li>Construct a stim_table for static gratings, and use `get_stimulus_parameter_values` to list the possible values for all stimulus parameters.</li>\n",
    "    <li>Create a `presentationwise_spike_counts` table for these stimuli, using a single bin covering the full duration of the presentation. Convert the output to a dataframe (`to_dataframe` method), and merge to the stim table to link the spike counts to the stimulus parameters.</li>\n",
    "    <li>Follow the examples below to show the tuning of the cell across two and three dimensions of stimulus parameters, respectively.</li>\n",
    "    <li>Explore variations on these plots by changing which columns are assigned to the `x`, `hue`, and `col` parameters. You can also show a single plot with one stimulus parameter left out to aggregate across that parameter. Which combination do you feel represents the data most intuitively? (We'll always want to keep `y=\"spike_counts\"`, since that is the dependent variable here.)</li>\n",
    "    <li>If you have time, follow the same steps for driting gratings for the same cell and compare the results.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint: Tuning across two stimulus dimensions**\n",
    "\n",
    "First, assign to the variable `data` a subset of the spike counts dataframe for a specific unit id and spatial frequency. Then run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "y = \"spike_counts\"\n",
    "x = \"orientation\"\n",
    "hue = \"phase\"\n",
    "sns.pointplot(data=data, x=x, y=y, hue=hue, dodge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint: Tuning across three stimulus dimensions**\n",
    "\n",
    "This time, assign to the variable `data` a subset of the spike counts dataframe containing all data for a single unit. Then run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to ignore the 'null' sweeps. By setting them to NaN, seaborn will automatically ignore them.\n",
    "data = data.replace('null', np.nan)\n",
    "y = \"spike_counts\"\n",
    "x = \"orientation\"\n",
    "hue = \"phase\"\n",
    "col = \"spatial_frequency\"\n",
    "sns.catplot(data=data, col=col, x=x, y=y, hue=hue, col_wrap=3, kind='point')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allensdk3]",
   "language": "python",
   "name": "conda-env-allensdk3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
