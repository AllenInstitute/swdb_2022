{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <img src=\"../resources/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">Regression Tutorial SWDB 2022 </h1> \n",
    "<h3 align=\"center\">Friday, August 26, 2022</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "Machine learning has many canonical problem types that we will discuss in these tutorials.  These include Regression, Classification, Clustering, and Dimension Reduction.  This tutorial is focused on Regression.\n",
    "</p>\n",
    "<p>\n",
    "    Regression is an example of a Supervised Learning problem.  In a regression problem, we are given $N$ pairs of data points $(\\vec{x}_i, y_i)$ where $i \\in [1,N]$.  We want to develop a function $f(\\vec{x})$ such that $f(\\vec{x}_i)\\approx y_i$ for each pair of points in the data set. The purpose of this function is to provide us with a model of how the data points $\\vec{x}_i$ affect $y_i$. This allows us to learn the degree to which $\\vec{x}_i$ has predictive power of $y_i$ and can tell you whether and how these data are correlated with each other.\n",
    "    </p>\n",
    "    <p>\n",
    "    The simplest regression problem is linear regression, in which we try to create the function $f$ by linearly combining a set of functions that act on the points $x$.\n",
    "\n",
    "$f(\\vec{x}_i) = \\sum_j w_j \\phi(\\vec{x}_i)$\n",
    "\n",
    "The functions $\\phi(\\vec{x})$ are chosen according to the analysis.  They are often called \"features\".  The coefficients $w_j$ are called \"weights\". You may be familiar with a simple version of linear regression, where the functions $\\phi$ are chosen to be the identity and a constant.  When the input space is also one dimensional, our function to fit becomes:\n",
    "\n",
    "$f(x) = w x + b$\n",
    "</p>\n",
    "<p>\n",
    "    This problem is solved by minimizing an \"error function\" function $E$ such that $f$ most closely approximates the data points $y_i$ on the inputs $\\vec{x}_i$.  This error function is simply the squared difference between $y$ and $f(\\vec{x})$.\n",
    "\n",
    "$E = \\frac{1}{2} \\sum_i \\left | y_i - f\\left ( \\vec{x}_i \\right ) \\right |^2 = \\frac{1}{2} \\sum_i \\left | y_i - \\sum_j w_j \\phi (\\vec{x}_i ) \\right |^2 $\n",
    "</p>\n",
    "<p>\n",
    "    This particular problem has an exact analytic solution that is easy to implement, but in this tutorial, we will look at how to perform regression using the `scikit-learn` Python package.  `scikit-learn` has many regression algorithms in common use built in, most of which do not have simple analytic solutions.  In addition, other packages have adopted the `scikit-learn` style interface.  One advantage of this is that multiple algorithms can be deployed with the same code.\n",
    "\n",
    "The `scikit-learn` website:  http://scikit-learn.org/stable/\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import general packages we'll need in this tutorial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "We're going to provide a simple example with fake data and then use the same model to fit data from the Brain Observatory.  We will attempt to model the data using an $n$th order polynomial of a single variable:\n",
    "</p>\n",
    "<p>\n",
    "$f_n(x) = \\sum_{i=0}^n a_i x^i$\n",
    "</p>\n",
    "<p>\n",
    "i.e.\n",
    "</p>\n",
    "<p>\n",
    "$f_1(x) = a_0 + a_1 x$\n",
    "</p>\n",
    "<p>\n",
    "$f_2(x) = a_0 + a_1 x + a_2x^2$\n",
    "</p>\n",
    "<p>\n",
    "$\\dots$\n",
    "</p>\n",
    "<p>\n",
    "First we generate some example data.  This will be the true model of the data.  (In a real problem, we won't know this function; we're trying to fit it.)\n",
    "</p>\n",
    "<p>\n",
    "$F(x) = sin(2\\pi x)$\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bins = np.linspace(0,1.0, 100)\n",
    "\n",
    "def f_true(xt): \n",
    "    return np.sin(2.0*np.pi*xt)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_bins, f_true(x_bins))\n",
    "ax.set_ylabel('f_true(x)')\n",
    "ax.set_xlabel('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "Now we generate some 'data' from this function.\n",
    "    </p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "\n",
    "x = np.sort(np.random.random(n))\n",
    "y = f_true(x) + 1.0*np.random.normal(size=n)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, 'o')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xlabel('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "<h3>Fitting a first order polynomial.</h3>\n",
    "</p>\n",
    "<p>\n",
    "Before we fit any models, we need to separate the data into train, validate, and test sets.  This is so that we can train the model (train), perform comparisons between different models and select the most appropriate one (validate), and test the performance of our finalmodel (test).\n",
    "</p>\n",
    "<p>\n",
    "`scikit-learn` has a function we can use called `train_test_split`.  We use this function twice in order to generate a validation set. Note how we split the data in half to create our training set, and split the remainder in half again to create the validation and testing sets.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(x, y, train_size=0.5)\n",
    "x_validate, x_test, y_validate, y_test = train_test_split(x_validate, y_validate, test_size=0.5)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(15,2))\n",
    "ax[0].plot(x_train, y_train, 'o')\n",
    "ax[1].plot(x_validate, y_validate, 'o')\n",
    "ax[2].plot(x_test, y_test, 'o')\n",
    "\n",
    "ax[0].set_title('Train')\n",
    "ax[1].set_title('Validate')\n",
    "ax[2].set_title('Test')\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_ylim(-4, 4)\n",
    "    ax[i].set_xlabel('x')\n",
    "    ax[i].set_ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "In ordert to fit the model, we need to create the object that will manage the fitting.  We are going to use the `LinearRegression` model from `sklearn.linear_model`.  Fitting works by calling the `fit` method with the data.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "We reshape `x` in the `fit` method because it expects a two dimensional array of shape (samples, dimensions).\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression()\n",
    "regression.fit(x_train.reshape(-1, 1), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "Now we compare the result to the validation set. Calling the \"predict\" method in our linear regression object will return $f(x)$ given the passed $x$. In other words, it will predict what are the data points $y$ you ought to observe given the data points $x$. We will plot the points predicted by the model together with the points in our validation set to see how well the model performed.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_validate, y_validate, 'o')\n",
    "predicted_y = regression.predict(x_bins.reshape(-1,1))\n",
    "ax.plot(x_bins.reshape(-1,1), predicted_y, '-')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylim(-4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "That's ok, but we could clearly do better.  Let's try multiple orders of polynomials so that we can compare them with the validation set.\n",
    "</p>\n",
    "<p>\n",
    "     We define a function `nth_polynomial` in order to create input data whose rows are data points and whose columns are the terms in the polynomial ($x$, $x^2$, $x^3$, $\\dots$)\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nth_polynomial(x, n):\n",
    "    return np.stack([x**i for i in range(1, n+1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_order = 9\n",
    "\n",
    "regression_list = [LinearRegression() for ind in range(max_order)]\n",
    "for ind, regression in enumerate(regression_list):\n",
    "    x_nth = nth_polynomial(x_train, ind+1)\n",
    "    regression.fit(x_nth, y_train)\n",
    "    \n",
    "fig, ax = plt.subplots(3,3, figsize=(15,15))\n",
    "\n",
    "for ind, regression in enumerate(regression_list):\n",
    "    xi = ind%3\n",
    "    yi = ind//3\n",
    "    x_nth = nth_polynomial(x_bins, ind+1)\n",
    "    ax[yi, xi].plot(x_train, y_train, 'o')\n",
    "    ax[yi, xi].plot(x_bins, regression.predict(x_nth))\n",
    "    ax[yi, xi].set_xlabel('x')\n",
    "    ax[yi, xi].set_ylabel('y')\n",
    "    ax[yi, xi].set_title('order '+str(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "Here are the models of various degree plotted against the training set. It seems like the fit improves as the order improves, but beware! Using a model with too many parameters for your data may improve the fit for your training set, but your model may become so finely tuned to the training set in particular that it is not generalizable. This is a problem known as \"overfitting.\"\n",
    "</p>\n",
    "<p>\n",
    "To demonstrate, we plot these models against the validation set.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,3, figsize=(15,15))\n",
    "\n",
    "for ind, regression in enumerate(regression_list):\n",
    "    xi = ind%3\n",
    "    yi = ind//3\n",
    "    x_nth = nth_polynomial(x_bins, ind+1)\n",
    "    ax[yi, xi].plot(x_validate, y_validate, 'o')\n",
    "    ax[yi, xi].plot(x_bins, regression.predict(x_nth))\n",
    "    ax[yi, xi].set_xlabel('x')\n",
    "    ax[yi, xi].set_ylabel('y')\n",
    "    ax[yi, xi].set_title('order '+str(ind+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "To quantify how well each of these models performs, we calculate the $R^2$ of the fit by calling the \"score\" method for each regression.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_vals = []\n",
    "\n",
    "for ind, regression in enumerate(regression_list):\n",
    "    x_nth = nth_polynomial(x_validate, ind+1)\n",
    "    R2 = regression.score(x_nth, y_validate)\n",
    "    R2_vals.append(R2)\n",
    "\n",
    "order = np.arange(1,max_order+1)\n",
    "fig, ax = plt.subplots(1,3, figsize=(15,2))\n",
    "ax[0].plot(order, R2_vals)\n",
    "ax[0].set_ylabel('Validation $R^2$')\n",
    "ax[0].set_xlabel('polynomial order')\n",
    "\n",
    "best_model_index = np.argmax(R2_vals)\n",
    "regression_best = regression_list[best_model_index]\n",
    "\n",
    "ax[1].plot(x_validate, y_validate, 'o')\n",
    "x_nth = nth_polynomial(x_bins, best_model_index+1)\n",
    "ax[1].plot(x_bins, regression_best.predict(x_nth))\n",
    "ax[1].set_ylabel('y_validate')\n",
    "ax[1].set_xlabel('x_validate')\n",
    "\n",
    "\n",
    "ax[2].plot(x_test, y_test, 'o')\n",
    "ax[2].plot(x_bins, regression_best.predict(x_nth))\n",
    "ax[1].set_ylabel('y_test')\n",
    "ax[1].set_xlabel('x_test')\n",
    "\n",
    "print(\"Best model is order:  {}\".format(best_model_index+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "<h2>Cross validation</h2>\n",
    "<p>\n",
    "We just used our \"validation\" data set to try to determine how well each of our models ggeneralizes to other data, but in fact, <code>scikit-learn</code> has built-in functions to make validation very simple! We can use our training data set to perform <b>cross validation</b>, where our model is fit multiple times on different subsets of the training data and the performance is compared across all subsets. This is similar to what we did above when we compared the training data to the validation data, and allows us to measure how consistent our model is.\n",
    "</p>\n",
    "<p>\n",
    "    Here, we perform cross validation with the functions <code>cross_validate</code> and <code>KFold</code>. <code>cross_validate</code> performs cross validation and returns a dictionary of scores over folds. <code>KFold</code> provides an iterator that produces indices that split the data into train and test folds.\n",
    "</p>\n",
    "<p>\n",
    "In the following, we'll ignore the data set we labeled \"validate\" above. In fact, this additional data set is unneccessary as data used for validation is part of the cross validation separation of the training set in the code below. In the future, you only need to split your data into training and testing sets!\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mean_error = np.zeros_like(regression_list)\n",
    "\n",
    "for ind, regression in enumerate(regression_list):\n",
    "    x_nth = nth_polynomial(x_train, ind+1)\n",
    "    cv_dict = cross_validate(regression, x_nth, y_train, cv=4)\n",
    "    cv_mean_error[ind] = np.mean(cv_dict['test_score'])\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(cv_mean_error)\n",
    "ax.set_ylabel('Cross Validation $<R^2>$')\n",
    "ax.set_xlabel('polynomial order')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "We can do the same analysis with `KFold`.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=4)\n",
    "\n",
    "scores = np.zeros_like(regression_list)\n",
    "\n",
    "for ind, regression in enumerate(regression_list):\n",
    "    scores_temp = []\n",
    "    for train, test in folds.split(x_train):\n",
    "        x_nth = nth_polynomial(x_train[train], ind+1)\n",
    "        regression.fit(x_nth, y_train[train])\n",
    "        x_nth = nth_polynomial(x_train[test], ind+1)\n",
    "        scores_temp.append(regression.score(x_nth, y_train[test]))\n",
    "    scores[ind] = np.mean(scores_temp)\n",
    "        \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(scores)\n",
    "ax.set_ylabel('Cross Validation $<R^2>$')\n",
    "ax.set_xlabel('polynomial order')\n",
    "# ax.set_ylim(-0.25, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "Now that we know the best model, we can apply it to the test data.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_index = np.argmax(scores)\n",
    "regression_best = regression_list[best_model_index]\n",
    "x_nth = nth_polynomial(x_train, best_model_index+1)\n",
    "regression_best.fit(x_nth, y_train)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_test, y_test, 'o')\n",
    "x_nth = nth_polynomial(x_bins, best_model_index+1)\n",
    "ax.plot(x_bins, regression_best.predict(x_nth))\n",
    "ax.set_ylabel('y_test')\n",
    "ax.set_xlabel('x_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "Now let's try a simple example with the Allen Brain Observatory Visual Behavior Dataset.  We will try regressing the neural activity in the midbrain reticular nucleus (MRN) against the running speed of the animal.  \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import allensdk\n",
    "from allensdk.brain_observatory.\\\n",
    "    behavior.behavior_project_cache.\\\n",
    "    behavior_neuropixels_project_cache \\\n",
    "    import VisualBehaviorNeuropixelsProjectCache\n",
    "import os\n",
    "import platform\n",
    "platstring = platform.platform()\n",
    "\n",
    "data_dirname = 'visual-behavior-neuropixels'\n",
    "use_static = False\n",
    "if 'Darwin' in platstring or 'macOS' in platstring:\n",
    "    # macOS \n",
    "    data_root = \"/Volumes/Brain2022/\"\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "elif ('amzn' in platstring):\n",
    "    # then on AWS\n",
    "    data_root = \"/data/\"\n",
    "    data_dirname = 'visual-behavior-neuropixels-data'\n",
    "    use_static = True\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2022/\"\n",
    "\n",
    "# get the cache location\n",
    "cache_dir = os.path.join(data_root, data_dirname)\n",
    "\n",
    "\n",
    "cache = VisualBehaviorNeuropixelsProjectCache.from_s3_cache(cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to find which units have the sessions we are interested in, so we will need the units and sessions tables.\n",
    "units_table = cache.get_unit_table()\n",
    "ecephys_sessions_table = cache.get_ecephys_session_table()\n",
    "\n",
    "# First, we want to find a \"Good\" Session to look at;\n",
    "# For now, we are going to grab the one with the most MRN units.\n",
    "unit_by_session = units_table.join(ecephys_sessions_table,on = 'ecephys_session_id')\n",
    "unit_in = unit_by_session[(unit_by_session['structure_acronym']=='MRN') & (unit_by_session['experience_level']=='Familiar')]\n",
    "unit_count = unit_in.groupby([\"ecephys_session_id\"]).count()\n",
    "familiar_session_with_most_in_units = unit_count.index[np.argmax(unit_count['ecephys_probe_id'])]\n",
    "familiar_session_with_most_in_units\n",
    "\n",
    "# Actually import the data\n",
    "session = cache.get_ecephys_session(ecephys_session_id=familiar_session_with_most_in_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unit information\n",
    "session_units = session.get_units()\n",
    "# Channel information\n",
    "session_channels = session.get_channels()\n",
    "# And associate each unit with the channel on which it was found with the largest amplitude\n",
    "units_by_channels= session_units.join(session_channels,on = 'peak_channel_id')\n",
    "\n",
    "# Filter for good units in MRN\n",
    "this_units = units_by_channels[(units_by_channels.structure_acronym == 'MRN')\\\n",
    "                               &(units_by_channels['isi_violations']<0.5)\\\n",
    "                               &(units_by_channels['amplitude_cutoff']<0.1)\\\n",
    "                               &(units_by_channels['presence_ratio']>0.95)]\n",
    "# Get the spiketimes from these units as a dictionary\n",
    "this_spiketimes = dict(zip(this_units.index, [session.spike_times[ii] for ii in this_units.index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll take all the spikes that were recorded in the MRN. This is more-or-less like taking \"multi-unit\" activity from this area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the running speed data from this same time interval\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "running_timestamps = session.running_speed.timestamps\n",
    "running_speed = session.running_speed.speed[:-1]\n",
    "\n",
    "# Bin the spiking data from all MRN neurons\n",
    "all_counts = np.zeros((len(this_units),len(running_timestamps)-1))\n",
    "for ind, unit in enumerate(this_units.index):\n",
    "    unit_spiketimes = this_spiketimes[unit]\n",
    "    all_counts[ind,:] = np.histogram(unit_spiketimes,running_timestamps)[0]\n",
    "\n",
    "# Average the spike rates to get multiunit activity   \n",
    "avg_spike_counts = np.mean(all_counts, axis=0)\n",
    "avg_spike_rates = avg_spike_counts/np.diff(running_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look only at the data during active behavior\n",
    "# Don't run this cell if you want to look at the entire recording session!\n",
    "\n",
    "active_stims = session.stimulus_presentations[session.stimulus_presentations.stimulus_block==0 ]\n",
    "\n",
    "# Get the start and end time of active behavior\n",
    "session_start_time = np.min(active_stims.start_time)\n",
    "session_end_time = np.max(active_stims.start_time) \n",
    "\n",
    "# Get the running and spike data during this period\n",
    "active_inds = np.searchsorted(running_timestamps, [session_start_time, session_end_time])\n",
    "\n",
    "running_speed = running_speed[active_inds[0]:active_inds[1]]\n",
    "avg_spike_rates = avg_spike_rates[active_inds[0]:active_inds[1]]\n",
    "all_counts = all_counts[:,active_inds[0]:active_inds[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1,figsize=(30, 20))\n",
    "\n",
    "ax[0].plot(running_timestamps[:1000],running_speed[:1000])\n",
    "ax[0].set_ylabel('Speed (cm/s)')\n",
    "ax[0].set_xlabel('Time (s)')\n",
    "\n",
    "ax[1].plot(running_timestamps[:1000],avg_spike_rates[:1000])\n",
    "ax[1].set_ylabel('Spike rate (spk/s)')\n",
    "ax[1].set_xlabel('Time (s)')\n",
    "\n",
    "ax[2].plot(avg_spike_rates[:1000], running_speed[:1000], 'o')\n",
    "ax[2].set_ylabel('Speed (cm/s)')\n",
    "ax[2].set_xlabel('Spike rate (spk/s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the spike rates are a little discretized. This is because the time bins used (the same ones from the running data) are short enough that only a handful of spikes make it into each bin, so the spike count data is very discrete.\n",
    "\n",
    "You will notice that thinking of running speed as continuous may also not be the \"best\" way to go about analysis; perhapse we should consider it as a binary (running v. not running) variable. We will go over how to build this type of model in the classification tutorial!\n",
    "\n",
    "Still, perhaps there is a correlation here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_train, spikes_test, run_train, run_test = train_test_split(avg_spike_rates[:1000], running_speed[:1000], train_size=0.75)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,2))\n",
    "ax[0].plot(spikes_train, run_train, 'o')\n",
    "ax[1].plot(spikes_test, run_test, 'o')\n",
    "\n",
    "ax[0].set_title('Train')\n",
    "ax[1].set_title('Test')\n",
    "\n",
    "for i in range(2):\n",
    "    #ax[i].set_ylim(-4, 4)\n",
    "    ax[i].set_xlabel('Spike rates (spks/s)')\n",
    "    ax[i].set_ylabel('Running Speed (cm/s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, we don't need a separate validation set if we make use of the cross validation tools!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try changing the bin numbers in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_order1 = LinearRegression()\n",
    "lr_order1.fit(spikes_train.reshape(-1, 1), run_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_order1.intercept_, lr_order1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bins = np.linspace(np.min(spikes_train), np.max(spikes_train), 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(spikes_train, run_train, 'o', ms=1)\n",
    "ax.plot(x_bins, lr_order1.predict(x_bins.reshape(-1,1)))\n",
    "ax.set_xlabel('Spike Rate (spk/s)')\n",
    "ax.set_ylabel('Running Speed (cm/s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_order = 9\n",
    "\n",
    "lr_list = [LinearRegression() for ind in range(max_order)]\n",
    "for ind, lr in enumerate(lr_list):\n",
    "    spikes_nth_order = nth_polynomial(spikes_train, ind+1)\n",
    "    lr.fit(spikes_nth_order, run_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,3, figsize=(15,15))\n",
    "\n",
    "for ind, lr in enumerate(lr_list):\n",
    "    xi = ind%3\n",
    "    yi = ind//3\n",
    "    x_nth_order = nth_polynomial(x_bins, ind+1)\n",
    "    ax[yi, xi].plot(spikes_train, run_train, 'o')\n",
    "    ax[yi, xi].plot(x_bins, lr.predict(x_nth_order),'o')\n",
    "    ax[yi, xi].set_xlabel('Spike Rate (spks/s)')\n",
    "    ax[yi, xi].set_ylabel('Running Speed (cm/s)')\n",
    "    ax[yi, xi].set_ylim((-20, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mean_error = np.zeros_like(lr_list)\n",
    "\n",
    "for ind, regression in enumerate(lr_list):\n",
    "    x_nth = nth_polynomial(spikes_train, ind+1)\n",
    "    cv_dict = cross_validate(regression, x_nth, run_train, cv=4)\n",
    "    cv_mean_error[ind] = np.mean(cv_dict['test_score'])\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(cv_mean_error)\n",
    "ax.set_ylabel('Cross Validation $<R^2>$')\n",
    "ax.set_xlabel('polynomial order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_index = np.argmax(cv_mean_error)\n",
    "regression_best = lr_list[best_model_index]\n",
    "x_nth = nth_polynomial(spikes_train, best_model_index+1)\n",
    "regression_best.fit(x_nth, run_train)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(spikes_test, run_test, 'o')\n",
    "x_nth = nth_polynomial(x_bins, best_model_index+1)\n",
    "ax.plot(x_bins, regression_best.predict(x_nth))\n",
    "ax.set_ylabel('Running Speed (cm/s)')\n",
    "ax.set_xlabel('Spike Rate (spk/s)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Remember, the training set can be multi-dimensional! \n",
    "#### Try using a matrix of spike rates for every neuron as your training data, rather than the average spike rate across all neurons. How does it do at predicting running speed over time? Plotting the predicted running speed vs actual running speed to find out on some held out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
