{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"../resources/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">Classification Tutorial SWDB 2022 </h1> \n",
    "<h3 align=\"center\">Monday, August 29, 2022</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "This tutorial covers some general concepts in classification and highlights useful functionality in the sklearn package for performing classification.\n",
    "    </p>\n",
    "    <p>\n",
    "<b>Classification</b> is closely related to regression. In the case of regression, we're trying to discover a mapping from independent continuous variables onto dependent continuous variables. In the case of classification, we're trying to discover a mapping from independent continous variables onto dependent categorical (i.e. discrete) variables. \n",
    "    </p>\n",
    "    <p>\n",
    "<i>Whereas regression attempts to find the best fit to the data, classification emphasizes finding the best boundaries to separate classes.</i>\n",
    "    </p>\n",
    "    <p>\n",
    "One prominent use case in systems neuroscience is that <i>decoding is typically framed as a classification problem</i>. For example, mapping an activity vector (cell activity x number of neurons) onto some categorical feature that we believe is represented in that population activity. The category could be which stimulus out of a set of stimuli was presented on that trial, or the behavioral state of the animal (e.g. asleep versus awake, running versus stationary, engaged versus disengaged).\n",
    "    </p>\n",
    "\n",
    "In this tutorial you will learn:\n",
    "- How to use sklearn for linear classification\n",
    "- How to cross-validate your classifier\n",
    "- How to use non-linear classifiers, in this case K nearest neighbors\n",
    "- How to use these classifiers to decode stimulus identify in visual cortex.\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import datasets\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn import neighbors\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.datasets` provides the ability to generate synthetic data that have specific kinds of structure that are useful for understanding and validating the performance of various classification algorithms.\n",
    "\n",
    "Here, we'll generate a 2D dataset with partial overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_classification(n_features=2,n_redundant=0,random_state=1,n_samples=1000)\n",
    "        \n",
    "print(np.shape(X))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the shape of the training sets is X: (num_samples, num_dimensions) and y: (num_samples)\n",
    "\n",
    "This function can visualize the datasets we'll generate in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes(X,y):\n",
    "    \n",
    "    classes = np.unique(y)\n",
    "    num_classes = len(classes)\n",
    "    \n",
    "    color = 'rbgmyk'\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    for cl in range(num_classes):\n",
    "        plt.scatter(X[y==cl,0],X[y==cl,1],c=color[cl],edgecolor='none')\n",
    "    plt.xlim(X[:,0].min(),X[:,0].max())\n",
    "    plt.ylim(X[:,1].min(),X[:,1].max())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to split our data into a *train* and *test* set to ensure that our classifier can generalize to data that it hasn't yet seen. Again sklearn provides a straightforward function to make this split. Here, I'm telling the function that I want 20% of the data held-out for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train,X_test,y_train,y_test] = model_selection.train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first classification algorithm we'll try, and one typically worth trying first, is linear discriminant analysis. LDA will attempt to find a linear boundary between our classes.\n",
    "\n",
    "[Linear Discriminant Analysis](https://towardsdatascience.com/linear-discriminant-analysis-explained-f88be6c1e00b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LDA()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_hat = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function can visualize the test data that is correctly versus incorrectly classified.\n",
    "Correctly classified data are displayed as filled circles, whereas incorrectly classified data are displayed as open circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_performance(X,y,y_hat):\n",
    "    \n",
    "    classes = np.unique(y_test)\n",
    "    num_classes = len(classes)\n",
    "    \n",
    "    color = 'rbgmyk'\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    for cl in range(num_classes):\n",
    "        \n",
    "        is_class = y == cl\n",
    "        is_correct = y == y_hat\n",
    "        \n",
    "        plt.scatter(X[is_class & is_correct,0],X[is_class & is_correct,1],c=color[cl],edgecolor='none')\n",
    "        plt.scatter(X[is_class & ~is_correct,0],X[is_class & ~is_correct,1],c='none',edgecolor=color[cl])\n",
    "        \n",
    "    plt.xlim(X[:,0].min(),X[:,0].max())\n",
    "    plt.ylim(X[:,1].min(),X[:,1].max())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_performance(X_test,y_test,y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to visualize the actual decision boundary that was learned, this function will push many points on a grid through the classifier and display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classifier_boundary(classifier,X,num_classes=2):\n",
    "\n",
    "    (grid_x1, grid_x2) = np.meshgrid(np.linspace(X[:,0].min(),X[:,0].max(),80),np.linspace(X[:,1].min(),X[:,1].max(),80))\n",
    "    grid = np.vstack([grid_x1.reshape(-1),grid_x2.reshape(-1)]).T\n",
    "    grid_classes = classifier.predict(grid)   \n",
    "    \n",
    "    plot_classes(grid,grid_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classifier_boundary(classifier,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier essentially learns to classify the data based on whether the first dimension is greater than or less than zero.\n",
    "\n",
    "The next exercise illustrates an important aspect of training classifiers: since the classifier learns both the generalizable structure of the data that we're trying to capture as well as the specific variation (noise) in the training data, **the performance of a classifier can be no better on the test data than on the training data**. Typically, it's worse. This phenomenon is called **overfitting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "num_folds = 5\n",
    "\n",
    "X, y = datasets.make_classification(n_features=2,n_redundant=0,random_state=0,n_samples=20)\n",
    "\n",
    "scores = model_selection.cross_validate(classifier,X,y, cv=5, return_train_score=True)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(111)\n",
    "ax.bar([0,1],[np.mean(scores['train_score']),np.mean(scores['test_score'])],color='c')\n",
    "ax.set_xticks([0.5,1.5])\n",
    "ax.set_xticklabels(['Train','Test'],fontsize=16)\n",
    "ax.set_ylabel('Fraction Correct',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try playing with the number of samples in the dataset above. You'll notice that the gap between the performance on train and test sets gets smaller as the dataset gets larger. That happens because the sample dataset begins to look more like the full population, so large train and test set should have very similar distributions. In other words, as the training set becomes infinitely large, it becomes impossible that the test set encounters a part of the distribution that is not represented in the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try a dataset that isn't so easily separated by a linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_moons(noise=0.2,random_state=0,n_samples=1000)\n",
    "    \n",
    "plot_classes(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train,X_test,y_train,y_test] = model_selection.train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "classifier = LDA()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_hat_lda = classifier.predict(X_test)\n",
    "\n",
    "plot_test_performance(X_test,y_test,y_hat_lda)\n",
    "plot_classifier_boundary(classifier,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a non-linear classifier. K-nearest neighbors is a very straightforward non-linear classifier that just uses the class mode of the closest data points in the training set.\n",
    "\n",
    "[K-nearest neighbors](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = neighbors.KNeighborsClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "y_hat_knn = classifier.predict(X_test)\n",
    "\n",
    "plot_test_performance(X_test,y_test,y_hat_knn)\n",
    "plot_classifier_boundary(classifier,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the KNN classifier depends on the number of neighbors that are considered for deciding class membership. We can determine the best value of K through **validation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_to_try = np.arange(2,250,1)\n",
    "val_performance = np.zeros(np.shape(k_to_try))\n",
    "for ki, k in enumerate(k_to_try):\n",
    "    \n",
    "    classifier = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    scores = model_selection.cross_validate(classifier,X_train,y_train, cv=3)\n",
    "    \n",
    "    val_performance[ki] = np.mean(scores['test_score'])\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(k_to_try,val_performance,'ro')\n",
    "plt.xlabel('K',fontsize=16)\n",
    "plt.ylabel('Validation Performance',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the best value of K from validation to see how well it generalizes to the hold-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_K = k_to_try[np.argmax(val_performance)]\n",
    "\n",
    "classifier = neighbors.KNeighborsClassifier(n_neighbors=best_K)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "y_hat = classifier.predict(X_test)\n",
    " \n",
    "print(\"Best K: \" + str(best_K))\n",
    "print(\"Validation Performance: \" + str(val_performance.max()))\n",
    "print(\"Test Performance: \" + str(np.mean(y_test == y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quantitatively compare the performance of LDA and KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = np.array([\n",
    "                          (y_test==y_hat_lda).mean(),\n",
    "                          (y_test==y_hat_knn).mean()\n",
    "                        ])\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(111)\n",
    "ax.bar([0,1],test_accuracy,color='c')\n",
    "ax.set_xticks([0.5,1.5])\n",
    "ax.set_xticklabels(['LDA','KNN'],fontsize=16)\n",
    "ax.set_ylabel('Fraction Correct',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more types of datasets you can make with scikit-learn, many of which are not linearly classifiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_circles(noise=0.1, factor=0.5, random_state=1,n_samples=1000)\n",
    "    \n",
    "plot_classes(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at a dataset with more than two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_blobs(n_features=2, centers=3,random_state=4,n_samples=1000)\n",
    "       \n",
    "plot_classes(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train,X_test,y_train,y_test] = model_selection.train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "classifier = neighbors.KNeighborsClassifier()\n",
    "classifier.fit(X_train,y_train) \n",
    "y_hat = classifier.predict(X_test)\n",
    "\n",
    "plot_test_performance(X_test,y_test,y_hat) \n",
    "plot_classifier_boundary(classifier,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the red and blue classes overlap, but neither overlaps with the green class. One method commonly used to determine which classes are more difficult for a classifier to distinguish is to make a \"confusion matrix.\" This is simply a matrix comparing the actual class a datapoint belongs to the class that is predicted by the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "C = confusion_matrix(y_test,y_hat)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(111)\n",
    "cax = ax.imshow(C,interpolation='none',origin='lower',vmin=0,vmax=C.max())\n",
    "ax.set_xlabel('Actual Class',fontsize=16)\n",
    "ax.set_ylabel('Predicted Class',fontsize=16)\n",
    "ax.set_xticks(range(3))\n",
    "ax.set_xticklabels(['Red','Blue','Green'],fontsize=16)\n",
    "ax.set_yticks(range(3))\n",
    "ax.set_yticklabels(['Red','Blue','Green'],fontsize=16)\n",
    "plt.colorbar(cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side note: Classification is related to another technique called clustering. Classification is performed when you have class labels, whereas clustering is performed when you do not. The former is known as supervised learning and the latter is known as unsupervised learning.\n",
    "\n",
    "sklearn, as you might have guess, has a number of built in clustering algorithms. As with classification, different algorithms make different underlying assumptions about the data at hand. You can read about these here: https://scikit-learn.org/stable/modules/clustering.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>\n",
    "\n",
    "### Once again, lets try to decoding in the Visual Behavior dataset.\n",
    "    \n",
    "<p>\n",
    "    Specifically, we will try and decode which image was presented to a mouse during a string of behavior trials\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import allensdk\n",
    "from allensdk.brain_observatory.\\\n",
    "    behavior.behavior_project_cache.\\\n",
    "    behavior_neuropixels_project_cache \\\n",
    "    import VisualBehaviorNeuropixelsProjectCache\n",
    "import os\n",
    "import platform\n",
    "platstring = platform.platform()\n",
    "\n",
    "data_dirname = 'visual-behavior-neuropixels'\n",
    "use_static = False\n",
    "if 'Darwin' in platstring or 'macOS' in platstring:\n",
    "    # macOS \n",
    "    data_root = \"/Volumes/Brain2022/\"\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "elif ('amzn' in platstring):\n",
    "    # then on AWS\n",
    "    data_root = \"/data/\"\n",
    "    data_dirname = 'visual-behavior-neuropixels-data'\n",
    "    use_static = True\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2022/\"\n",
    "\n",
    "# get the cache location\n",
    "cache_dir = os.path.join(data_root, data_dirname)\n",
    "\n",
    "#cache = VisualBehaviorNeuropixelsProjectCache.from_s3_cache(cache_dir=cache_dir)\n",
    "cache = VisualBehaviorNeuropixelsProjectCache.from_local_cache(\n",
    "            cache_dir=cache_dir, use_static_cache=use_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to find the \"familiar\" session that contains the most V1 units. \n",
    "area = 'VISp'\n",
    "# You have actually seen this code before, so we won't spend time on it...\n",
    "units_table = cache.get_unit_table()\n",
    "ecephys_sessions_table = cache.get_ecephys_session_table()\n",
    "\n",
    "# For now, we are going to grab the one with the most V! units.\n",
    "unit_by_session = units_table.join(ecephys_sessions_table,on = 'ecephys_session_id')\n",
    "unit_in = unit_by_session[(unit_by_session['structure_acronym']==area) &\\\n",
    "                          (unit_by_session['experience_level']=='Familiar') &\\\n",
    "                          (unit_by_session['isi_violations']<.5)&\\\n",
    "                          (unit_by_session['amplitude_cutoff']<0.1)&\\\n",
    "                          (unit_by_session['presence_ratio']>0.95)]\n",
    "unit_count = unit_in.groupby([\"ecephys_session_id\"]).count()\n",
    "familiar_session_with_most_in_units = unit_count.index[np.argmax(unit_count['ecephys_probe_id'])]\n",
    "# Actually imort the data\n",
    "session = cache.get_ecephys_session(ecephys_session_id=familiar_session_with_most_in_units)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unit information\n",
    "session_units = session.get_units()\n",
    "# Channel information\n",
    "session_channels = session.get_channels()\n",
    "# And accosiate each unit with the channel on which it was found with the largest amplitude\n",
    "units_by_channels= session_units.join(session_channels,on = 'peak_channel_id')\n",
    "\n",
    "# Filter for units in primary visual cortex\n",
    "this_units = units_by_channels[(units_by_channels.structure_acronym == area)\\\n",
    "                               &(units_by_channels['isi_violations']<.5)\\\n",
    "                               &(units_by_channels['amplitude_cutoff']<0.1)\\\n",
    "                               &(units_by_channels['presence_ratio']>0.95)]\n",
    "# Get the spiketimes from these units as a dictionary\n",
    "this_spiketimes = dict(zip(this_units.index, [session.spike_times[ii] for ii in this_units.index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, get the stimulus table for the behavior session:\n",
    "active_stims = session.stimulus_presentations[session.stimulus_presentations.stimulus_block==0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with PCA, we need to construct a matrix X (𝑇,𝑛) row per time sample and one column per neuron/dimension.\n",
    "\n",
    "Once again, the time scale that we choose will have a major impact on what we can learn from our classifier. In this case, we are going consider each timepoint as a trial, looking at the number of spikes from each neuron in the 250 ms after an image is show.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first need a function that counts the number of times a neuron spikes within a given time window\n",
    "def count_spikes_after_event(spikeTimes,eventTime,window):\n",
    "    startInd = np.searchsorted(spikeTimes, eventTime)\n",
    "    endInd = np.searchsorted(spikeTimes, eventTime+window)\n",
    "    count = len(spikeTimes[startInd:endInd])\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and empty variable X\n",
    "X = np.zeros((len(active_stims),len(this_spiketimes)))\n",
    "# This Loop is a little slow...be patient\n",
    "# Loop Through both trials and units, counting the number of spikes\n",
    "for jj,key in enumerate(this_spiketimes):\n",
    "    # Loop through the trials\n",
    "    for ii, trial in active_stims.iterrows():\n",
    "        # Count the number of spikes per trial. \n",
    "        X[ii,jj] = count_spikes_after_event(this_spiketimes[key],trial.start_time,.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"unique\" command in numpy has a handy feature that converts non-numeric catigories to numeric ones. \n",
    "\n",
    "\"Unique\" returns a list of each unique value in a list. The inverse of the unique function provides the index needed to ruturn that list back to its origional state. Convienetly, for a discrete variable, this means that the inverse returned by the unique function provides a integer catigory marker for non-integer data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[unq,cat]= np.unique(active_stims.image_name,return_inverse=True)\n",
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should take a moment to note that dimensionality reduction techniques, like PCA, are often useful in assessing how successful a decoding algorithm might be. If you can easily visuallize stratification in your data, it will likely be easy for a classifier to determine boundries between groups in your data. Lets take a moment to look at the first two PCs of our response matrix, X. Do you think we are going to have much luck with our classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "trans = pca.fit_transform(X)\n",
    "plt.scatter(trans[:,0],trans[:,1],c = cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this is likely going to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exersize (1): Choose a sklearn classifier! LDA and KNN are clearly some favorites, but if you are feeling fancy you are welcome to look at others here: https://scikit-learn.org/stable/supervised_learning.html\n",
    "\n",
    "You have a matrix \"X: and classes \"cat\". Seperate these into training and testing data, then fit and evaluate your classifier. What is your error rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exersize (2): Construct a confusion and plot a confusion matrix for your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exersize (3): V1 was a (maybe too) easy example for this problem. Try playing around with different brain areas to if they do as well (hint: change the \"area\" variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally (if there is time), its worth noting at some classifiers can measure how important an particular feature was in making their classification. \n",
    "\n",
    "One example of this is a decision tree. Decision trees are useful because the results are easily interpretable - in the end, you get a series of choices on the values of individual features that tell you which class to assign any given datapoint to. They're called decision trees because you always start at the same point (\"the root\") and each consecutive choice leads you down a particular branch, until you arrive at a class assignment (\"the leaves\").\n",
    "\n",
    "A Decision tree object also returns a \"feature_imortances_\" variable. Feature importance (see \"Gini Importance\") gives a sense of how heavily each feature is weighted in the decision tree. In this case, It tells us how important each cell is in the classifier's decision process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(random_state=0)\n",
    "classifier = classifier.fit(X_train, cat_train)\n",
    "\n",
    "plt.plot(classifier.feature_importances_,'.')\n",
    "plt.xlabel(\"Cell ID\")\n",
    "plt.ylabel('Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
